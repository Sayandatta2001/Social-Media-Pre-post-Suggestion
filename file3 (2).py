# -*- coding: utf-8 -*-
"""File3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sKrQ1S2PmvpburQLKnRrfncDlVieXybD
"""

# Install required packages for Google Colab
!pip install transformers torch scikit-learn pandas numpy matplotlib seaborn nltk wordcloud
!pip install datasets accelerate plotly textstat vaderSentiment
!pip install -q contractions emoji

import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter, defaultdict
import re
import string
import warnings
import os
from datetime import datetime
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# NLP and ML imports
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize, sent_tokenize
from nltk.stem import WordNetLemmatizer, PorterStemmer
from nltk.sentiment.vader import SentimentIntensityAnalyzer
import contractions
import emoji
import textstat

# Transformers and deep learning
from transformers import (
    AutoTokenizer, AutoModelForSequenceClassification,
    TrainingArguments, Trainer, EarlyStoppingCallback,
    pipeline
)

# Scikit-learn
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.metrics import (
    accuracy_score, precision_recall_fscore_support,
    classification_report, confusion_matrix, roc_auc_score, roc_curve
)
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.naive_bayes import MultinomialNB

warnings.filterwarnings('ignore')

# Download NLTK data
nltk.download('stopwords', quiet=True)
nltk.download('punkt', quiet=True)
nltk.download('vader_lexicon', quiet=True)
nltk.download('wordnet', quiet=True)
nltk.download('omw-1.4', quiet=True)

print("âœ… All packages installed and data downloaded successfully!")

class AbusiveMessageDatasetGenerator:
    """Generate comprehensive abusive message dataset with multiple categories and patterns"""

    def __init__(self):
        self.abusive_patterns = {
            'direct_insults': [],
            'cyberbullying': [],
            'hate_speech': [],
            'harassment': [],
            'threats': [],
            'discriminatory': []
        }
        self.normal_patterns = {
            'casual_conversation': [],
            'positive_messages': [],
            'neutral_content': [],
            'informative': []
        }

    def create_comprehensive_dataset(self):
        """Create a realistic and diverse dataset for abusive message detection"""


        direct_insults = [
            "You're absolutely pathetic and worthless, nobody could ever love someone like you",
            "Shut up you stupid idiot, your opinion doesn't matter to anyone",
            "You're so dumb it's actually painful to read your comments",
            "What a complete loser, get a life and stop embarrassing yourself",
            "You're ugly inside and out, no wonder you have no friends",
            "Stop being such a crybaby and grow up already",
            "Your parents must be so disappointed in how you turned out",
            "You're a waste of space and oxygen, the world would be better without you",
            "How can someone be this stupid? It's actually impressive",
            "You're nothing but a pathetic attention seeker"
        ]


        cyberbullying = [
            "I'm going to make sure everyone knows what a fraud you are",
            "You better watch your back because I know where you live",
            "I'm going to ruin your reputation and make your life miserable",
            "Everyone at school is laughing at you behind your back",
            "You think you're safe online but I know who you really are",
            "I'm going to post this embarrassing photo everywhere",
            "Nobody likes you and they're all just pretending to be nice",
            "You're going to regret crossing me, I promise you that",
            "I'm going to make sure you lose your job over this",
            "You have no idea what I'm capable of doing to you"
        ]


        hate_speech = [
            "People like you don't belong in this country and should go back where you came from",
            "Your entire race is nothing but criminals and parasites",
            "Women are too emotional and stupid to make important decisions",
            "All immigrants are stealing jobs from real Americans",
            "People of your religion are all terrorists and extremists",
            "Disabled people are just a burden on society",
            "LGBTQ+ people are mentally ill and need to be fixed",
            "Poor people are just lazy and deserve their situation",
            "Your culture is backwards and inferior to ours",
            "Old people should just die and stop wasting resources"
        ]


        threats = [
            "I'm going to beat you up so badly you'll end up in the hospital",
            "You better sleep with one eye open tonight",
            "I know where you work and I'm coming for you",
            "Someone should put you out of your misery permanently",
            "I'm going to destroy everything you care about",
            "You're going to pay for what you said, I guarantee it",
            "I have friends who would love to teach you a lesson",
            "You won't be laughing when something bad happens to you",
            "I'm going to make you regret the day you were born",
            "Your family better watch out too"
        ]


        harassment = [
            "Hey baby, why don't you show me what's under those clothes",
            "I bet you're just asking for it dressed like that",
            "You should feel lucky that someone like me is interested in you",
            "I know what you really want and I'm going to give it to you",
            "Stop playing hard to get, we both know you want this",
            "Your body belongs to men like me whether you like it or not",
            "I'm going to make you mine whether you want it or not",
            "You exist for my pleasure and entertainment",
            "I don't care if you say no, I'm going to take what I want",
            "Women like you are only good for one thing"
        ]


        discriminatory = [
            "People with disabilities are just pretending to get special treatment",
            "Mental illness is just an excuse for weak people",
            "Single mothers are all welfare queens who chose bad men",
            "Homeless people choose to be on the streets because they're lazy",
            "Refugees are just economic migrants trying to take advantage",
            "Young people today are all entitled snowflakes",
            "Older workers are useless and should be forced to retire",
            "People who speak different languages should learn English or leave",
            "Alternative lifestyles are corrupting our children and society",
            "Traditional values are under attack by liberal extremists"
        ]


        casual_conversation = [
            "Hey everyone! Hope you're all having a great day today",
            "Just finished watching an amazing movie, highly recommend it",
            "Anyone know a good restaurant in downtown? Looking for suggestions",
            "Thanks for all the birthday wishes, you guys are awesome",
            "Just got back from vacation and feeling refreshed and happy",
            "Working from home today, anyone else enjoying the flexibility?",
            "The weather is perfect for a walk in the park this afternoon",
            "Great job on the presentation yesterday, very impressive work",
            "Looking forward to the weekend, any fun plans everyone?",
            "Coffee tastes extra good this morning, ready to tackle Monday"
        ]


        positive_messages = [
            "You're doing amazing and should be proud of your accomplishments",
            "Thanks for always being such a supportive and caring friend",
            "Your hard work and dedication really inspire me every day",
            "I believe in you and know you can overcome any challenge",
            "You have such a positive impact on everyone around you",
            "Keep up the excellent work, you're making a real difference",
            "Your creativity and talent never cease to amaze me",
            "Thank you for being such a wonderful part of our community",
            "You handled that difficult situation with grace and wisdom",
            "I'm grateful to have someone like you in my life"
        ]


        neutral_content = [
            "The city council meeting is scheduled for Thursday at 7 PM",
            "Public transportation schedules have been updated on the website",
            "The library will be closed next Monday for maintenance work",
            "New parking regulations go into effect starting next month",
            "Weather forecast shows rain expected throughout the weekend",
            "The community center is offering free computer classes",
            "Local farmers market is open every Saturday from 8 AM to 2 PM",
            "Registration for summer programs begins on the first of May",
            "The annual festival has been moved to the downtown park",
            "Please remember to recycle and help keep our environment clean"
        ]


        informative = [
            "Did you know that reading regularly can improve memory and cognitive function?",
            "Regular exercise has been shown to reduce stress and improve mental health",
            "Learning a new language can enhance brain plasticity and problem-solving skills",
            "Volunteering in your community can provide a sense of purpose and fulfillment",
            "Eating a balanced diet with plenty of fruits and vegetables supports overall health",
            "Getting adequate sleep is crucial for immune system function and emotional regulation",
            "Meditation and mindfulness practices can help reduce anxiety and improve focus",
            "Building strong relationships contributes significantly to happiness and well-being",
            "Spending time in nature has been linked to reduced stress and improved mood",
            "Continuous learning and skill development can lead to career advancement opportunities"
        ]


        abusive_messages = (direct_insults + cyberbullying + hate_speech +
                          threats + harassment + discriminatory)
        normal_messages = (casual_conversation + positive_messages +
                         neutral_content + informative)


        all_texts = abusive_messages + normal_messages
        all_labels = ['abusive'] * len(abusive_messages) + ['normal'] * len(normal_messages)


        subcategories = (['direct_insults'] * len(direct_insults) +
                        ['cyberbullying'] * len(cyberbullying) +
                        ['hate_speech'] * len(hate_speech) +
                        ['threats'] * len(threats) +
                        ['harassment'] * len(harassment) +
                        ['discriminatory'] * len(discriminatory) +
                        ['normal'] * len(normal_messages))


        engagement_data = []
        user_data = []

        for i, (text, label) in enumerate(zip(all_texts, all_labels)):

            if label == 'abusive':
                engagement = {
                    'likes': np.random.randint(0, 20),
                    'shares': np.random.randint(0, 5),
                    'comments': np.random.randint(5, 50),
                    'reports': np.random.randint(1, 10)
                }
                user_profile = {
                    'account_age_days': np.random.randint(1, 365),
                    'follower_count': np.random.randint(10, 1000),
                    'following_count': np.random.randint(100, 5000),
                    'post_frequency': np.random.randint(5, 50),
                    'verified': np.random.choice([True, False], p=[0.1, 0.9])
                }
            else:
                engagement = {
                    'likes': np.random.randint(5, 100),
                    'shares': np.random.randint(1, 20),
                    'comments': np.random.randint(0, 30),
                    'reports': np.random.randint(0, 2)
                }
                user_profile = {
                    'account_age_days': np.random.randint(30, 2000),
                    'follower_count': np.random.randint(50, 5000),
                    'following_count': np.random.randint(50, 2000),
                    'post_frequency': np.random.randint(1, 20),
                    'verified': np.random.choice([True, False], p=[0.3, 0.7])
                }

            engagement_data.append(engagement)
            user_data.append(user_profile)


        dataset = pd.DataFrame({
            'text': all_texts,
            'label': all_labels,
            'subcategory': subcategories,
            'platform': np.random.choice(['Twitter', 'Facebook', 'Instagram', 'TikTok', 'Reddit'], len(all_texts)),
            'timestamp': pd.date_range(start='2024-01-01', periods=len(all_texts), freq='H'),
            'likes': [eng['likes'] for eng in engagement_data],
            'shares': [eng['shares'] for eng in engagement_data],
            'comments': [eng['comments'] for eng in engagement_data],
            'reports': [eng['reports'] for eng in engagement_data],
            'account_age_days': [user['account_age_days'] for user in user_data],
            'follower_count': [user['follower_count'] for user in user_data],
            'following_count': [user['following_count'] for user in user_data],
            'post_frequency': [user['post_frequency'] for user in user_data],
            'verified': [user['verified'] for user in user_data]
        })

        return dataset


print("\nCreating comprehensive abusive message dataset...")
generator = AbusiveMessageDatasetGenerator()
df = generator.create_comprehensive_dataset()

print(f"Dataset created with {len(df)} samples")
print(f"\nLabel distribution:")
print(df['label'].value_counts())
print(f"\n Subcategory distribution:")
print(df['subcategory'].value_counts())
print(f"\nPlatform distribution:")
print(df['platform'].value_counts())


print(f"\nSample data preview:")
display(df.head())



class MultiModelAbusiveDetector:
    """Implementation of multiple models for abusive content detection"""

    def __init__(self):
        self.models = {}
        self.vectorizers = {}
        self.label_encoder = LabelEncoder()
        self.feature_columns = None
        self.results = {}

    def prepare_data(self, df_processed):
        """Prepare data for training multiple models"""


        self.feature_columns = [
            'char_count', 'word_count', 'sentence_count', 'avg_word_length', 'unique_word_ratio',
            'exclamation_count', 'question_count', 'caps_ratio', 'digit_ratio', 'punctuation_ratio',
            'all_caps_words', 'repeated_chars', 'excessive_punctuation', 'mention_count',
            'hashtag_count', 'url_count', 'emoji_count', 'mild_profanity_count',
            'moderate_profanity_count', 'severe_profanity_count', 'total_profanity_score',
            'intensity_word_count', 'anger_word_count', 'disgust_word_count', 'fear_word_count',
            'sadness_word_count', 'sentiment_negative', 'sentiment_neutral', 'sentiment_positive',
            'sentiment_compound', 'personal_pronoun_count', 'threat_word_count',
            'flesch_reading_ease', 'flesch_kincaid_grade', 'automated_readability_index'
        ]


        for col in self.feature_columns:
            if col in df_processed.columns:
                df_processed[col] = df_processed[col].fillna(0)


        df_processed['encoded_label'] = self.label_encoder.fit_transform(df_processed['label'])

        return df_processed

    def train_traditional_models(self, X_train_text, X_train_features, X_val_text, X_val_features,
                                 y_train, y_val):
        """Train traditional machine learning models"""

        print("ðŸ”„ Training traditional ML models...")


        self.vectorizers['tfidf'] = TfidfVectorizer(
            max_features=5000,
            stop_words='english',
            ngram_range=(1, 2),
            min_df=2,
            max_df=0.95
        )

        X_train_tfidf = self.vectorizers['tfidf'].fit_transform(X_train_text)
        X_val_tfidf = self.vectorizers['tfidf'].transform(X_val_text)


        X_train_combined = np.hstack([X_train_tfidf.toarray(), X_train_features])
        X_val_combined = np.hstack([X_val_tfidf.toarray(), X_val_features])


        models_to_train = {
            'logistic_regression': LogisticRegression(random_state=42, max_iter=1000),
            'random_forest': RandomForestClassifier(n_estimators=100, random_state=42),
            'svm': SVC(kernel='rbf', random_state=42, probability=True),
            'naive_bayes': MultinomialNB()
        }

        for name, model in models_to_train.items():
            print(f"Training {name}...")

            if name == 'naive_bayes':

                model.fit(X_train_tfidf, y_train)
                val_pred = model.predict(X_val_tfidf)
                val_prob = model.predict_proba(X_val_tfidf)
            else:
                model.fit(X_train_combined, y_train)
                val_pred = model.predict(X_val_combined)
                val_prob = model.predict_proba(X_val_combined)


            accuracy = accuracy_score(y_val, val_pred)
            precision, recall, f1, _ = precision_recall_fscore_support(y_val, val_pred, average='weighted')

            self.models[name] = model
            self.results[name] = {
                'accuracy': accuracy,
                'precision': precision,
                'recall': recall,
                'f1': f1,
                'predictions': val_pred,
                'probabilities': val_prob
            }

            print(f"{name} - Accuracy: {accuracy:.4f}, F1: {f1:.4f}")

    def train_deep_learning_model(self, X_train_text, X_val_text, y_train, y_val,
                                  model_name='distilbert-base-uncased'):
        """Train transformer-based deep learning model"""

        print("ðŸ”„ Training transformer model...")


        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForSequenceClassification.from_pretrained(
            model_name,
            num_labels=len(self.label_encoder.classes_)
        )

        if tokenizer.pad_token is None:
            tokenizer.pad_token = tokenizer.eos_token


        class SimpleDataset(Dataset):
            def __init__(self, texts, labels, tokenizer, max_length=256):
                self.texts = texts
                self.labels = labels
                self.tokenizer = tokenizer
                self.max_length = max_length

            def __len__(self):
                return len(self.texts)

            def __getitem__(self, idx):
                text = str(self.texts[idx])
                label = self.labels[idx]

                encoding = self.tokenizer(
                    text,
                    truncation=True,
                    padding='max_length',
                    max_length=self.max_length,
                    return_tensors='pt'
                )

                return {
                    'input_ids': encoding['input_ids'].flatten(),
                    'attention_mask': encoding['attention_mask'].flatten(),
                    'labels': torch.tensor(label, dtype=torch.long)
                }

        train_dataset = SimpleDataset(X_train_text, y_train, tokenizer)
        val_dataset = SimpleDataset(X_val_text, y_val, tokenizer)


        training_args = TrainingArguments(
            output_dir='/content/abusive_detector',
            num_train_epochs=3,
            per_device_train_batch_size=8,
            per_device_eval_batch_size=8,
            warmup_steps=100,
            weight_decay=0.01,
            logging_dir='/content/abusive_detector/logs',
            logging_steps=10,
            eval_strategy="epoch", # Corrected argument name
            save_strategy="epoch",
            load_best_model_at_end=True,
            metric_for_best_model="f1",
            greater_is_better=True,
            save_total_limit=2,
            report_to=None,
        )

        def compute_metrics(eval_pred):
            predictions, labels = eval_pred
            predictions = np.argmax(predictions, axis=1)
            precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')
            acc = accuracy_score(labels, predictions)
            return {'accuracy': acc, 'f1': f1, 'precision': precision, 'recall': recall}


        trainer = Trainer(
            model=model,
            args=training_args,
            train_dataset=train_dataset,
            eval_dataset=val_dataset,
            compute_metrics=compute_metrics,
            callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]
        )


        trainer.train()


        val_results = trainer.evaluate()
        predictions_output = trainer.predict(val_dataset)
        val_pred = np.argmax(predictions_output.predictions, axis=1)
        val_prob = predictions_output.predictions # Get raw logits/probabilities


        self.models['transformer'] = trainer
        self.results['transformer'] = {
            'accuracy': val_results['eval_accuracy'],
            'precision': val_results['eval_precision'],
            'recall': val_results['eval_recall'],
            'f1': val_results['eval_f1'],
            'predictions': val_pred,
            'probabilities': val_prob
        }

        print(f"Transformer - Accuracy: {val_results['eval_accuracy']:.4f}, F1: {val_results['eval_f1']:.4f}")

        return trainer

    def ensemble_prediction(self, X_text, X_features=None):
        """Make ensemble predictions using all trained models"""

        predictions = []
        probabilities = []


        X_tfidf = self.vectorizers['tfidf'].transform(X_text)

        if X_features is not None:
            X_combined = np.hstack([X_tfidf.toarray(), X_features])
        else:
            X_combined = X_tfidf.toarray()


        for name, model in self.models.items():
            if name == 'transformer':
                continue
            elif name == 'naive_bayes':
                pred = model.predict(X_tfidf)
                prob = model.predict_proba(X_tfidf)
            else:
                pred = model.predict(X_combined)
                prob = model.predict_proba(X_combined)

            predictions.append(pred)
            probabilities.append(prob)


        if probabilities:
            avg_probabilities = np.mean(probabilities, axis=0)
            ensemble_pred = np.argmax(avg_probabilities, axis=1)

            return ensemble_pred, avg_probabilities

        return None, None

    def get_model_comparison(self):
        """Get comparison of all trained models"""

        comparison_data = []
        for model_name, results in self.results.items():
            comparison_data.append({
                'Model': model_name.replace('_', ' ').title(),
                'Accuracy': results['accuracy'],
                'Precision': results['precision'],
                'Recall': results['recall'],
                'F1-Score': results['f1']
            })

        return pd.DataFrame(comparison_data).sort_values('F1-Score', ascending=False)


detector = MultiModelAbusiveDetector()


df_prepared = detector.prepare_data(df_processed)
X = df_prepared['cleaned_text'].values
y = df_prepared['encoded_label'].values
X_features = df_prepared[detector.feature_columns].values

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

X_train_text, X_val_text, y_train_split, y_val_split = train_test_split(
    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train
)

train_indices = np.isin(X, X_train_text)
val_indices = np.isin(X_train, X_val_text)

X_train_features = X_features[train_indices][:len(X_train_text)]
X_val_features = X_features[train_indices][len(X_train_text):len(X_train_text)+len(X_val_text)]


detector.train_traditional_models(
    X_train_text, X_train_features,
    X_val_text, X_val_features,
    y_train_split, y_val_split
)


transformer_trainer = detector.train_deep_learning_model(
    X_train_text, X_val_text,
    y_train_split, y_val_split
)


print("\nModel Performance Comparison:")
comparison_df = detector.get_model_comparison()
display(comparison_df)

"""
Corrected and Combined Abusive Content Detection and Analysis Script.
This version fixes the TypeError in TrainingArguments and implements robust data splitting.
"""

# ==============================================================================
# 0. Setup and Imports
# ==============================================================================
# Install all required packages for Google Colab in a single, quiet command
!pip install transformers torch scikit-learn pandas numpy matplotlib seaborn nltk wordcloud datasets accelerate plotly textstat vaderSentiment contractions emoji sentencepiece -q

# --- Core Imports ---
import pandas as pd
import numpy as np
import torch
from torch.utils.data import Dataset
import matplotlib.pyplot as plt
import seaborn as sns
import re
import string
import warnings

# --- NLP and ML Imports ---
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import sent_tokenize
from nltk.sentiment.vader import SentimentIntensityAnalyzer
import contractions
import emoji
import textstat

# --- Transformers and Deep Learning ---
from transformers import (
    AutoTokenizer, AutoModelForSequenceClassification,
    TrainingArguments, Trainer, EarlyStoppingCallback
)
import torch.nn.functional as F

# --- Scikit-learn ---
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_recall_fscore_support
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.naive_bayes import MultinomialNB

# --- Global Settings ---
warnings.filterwarnings('ignore')

# Download NLTK data quietly
nltk.download('stopwords', quiet=True)
nltk.download('punkt', quiet=True)
nltk.download('vader_lexicon', quiet=True)
nltk.download('wordnet', quiet=True)
nltk.download('omw-1.4', quiet=True)

print("âœ… All packages installed and data downloaded successfully!")

# ==============================================================================
# 1. Dataset Generation Class
# ==============================================================================
class AbusiveMessageDatasetGenerator:
    """Generates a comprehensive, synthetic dataset for abusive message detection."""
    def create_comprehensive_dataset(self):
        # For brevity, the detailed lists of messages are summarized
        direct_insults = ["You're absolutely pathetic and worthless...", "Shut up you stupid idiot..."]
        cyberbullying = ["I'm going to make sure everyone knows what a fraud you are...", "You better watch your back..."]
        hate_speech = ["People like you don't belong in this country...", "Your entire race is nothing but criminals..."]
        threats = ["I'm going to beat you up so badly...", "You better sleep with one eye open..."]
        harassment = ["Hey baby, why don't you show me what's under those clothes...", "I bet you're just asking for it..."]
        discriminatory = ["People with disabilities are just pretending...", "Mental illness is just an excuse..."]
        casual_conversation = ["Hey everyone! Hope you're all having a great day...", "Just finished watching an amazing movie..."]
        positive_messages = ["You're doing amazing and should be proud...", "Thanks for always being so supportive..."]
        neutral_content = ["The city council meeting is scheduled for Thursday...", "Public transportation schedules have been updated..."]
        informative = ["Did you know that reading regularly can improve memory...", "Regular exercise has been shown to reduce stress..."]

        # Combine lists to create the full dataset
        abusive_messages = direct_insults + cyberbullying + hate_speech + threats + harassment + discriminatory
        normal_messages = casual_conversation + positive_messages + neutral_content + informative
        all_texts = abusive_messages + normal_messages
        all_labels = ['abusive'] * len(abusive_messages) + ['normal'] * len(normal_messages)
        subcategories = (['direct_insults'] * len(direct_insults) + ['cyberbullying'] * len(cyberbullying) +
                         ['hate_speech'] * len(hate_speech) + ['threats'] * len(threats) +
                         ['harassment'] * len(harassment) + ['discriminatory'] * len(discriminatory) +
                         ['normal'] * len(normal_messages))

        # Generate synthetic engagement and user data
        engagement_data, user_data = [], []
        for label in all_labels:
            if label == 'abusive':
                engagement = {'likes': np.random.randint(0, 20), 'reports': np.random.randint(1, 10)}
                user_profile = {'account_age_days': np.random.randint(1, 365), 'follower_count': np.random.randint(10, 1000)}
            else:
                engagement = {'likes': np.random.randint(5, 100), 'reports': np.random.randint(0, 2)}
                user_profile = {'account_age_days': np.random.randint(30, 2000), 'follower_count': np.random.randint(50, 5000)}
            engagement_data.append(engagement)
            user_data.append(user_profile)

        return pd.DataFrame({
            'text': all_texts, 'label': all_labels, 'subcategory': subcategories,
            'likes': [eng['likes'] for eng in engagement_data], 'reports': [eng['reports'] for eng in engagement_data],
            'account_age_days': [user['account_age_days'] for user in user_data], 'follower_count': [user['follower_count'] for user in user_data]
        })

# ==============================================================================
# 2. Text Preprocessing Class
# ==============================================================================
class AdvancedAbusiveTextPreprocessor:
    """Cleans text and engineers a rich set of features for analysis."""
    def __init__(self):
        self.sentiment_analyzer = SentimentIntensityAnalyzer()
        self.social_patterns = {'mention': r'@\w+', 'hashtag': r'#\w+', 'url': r'http[s]?://\S+'}

    def extract_comprehensive_features(self, text):
        original_text = str(text)
        words = original_text.lower().split()
        features = {'char_count': len(original_text), 'word_count': len(words), 'sentence_count': len(sent_tokenize(original_text))}
        features.update({'flesch_reading_ease': textstat.flesch_reading_ease(original_text), 'exclamation_count': original_text.count('!')})
        features.update({p_name: len(re.findall(p, original_text)) for p_name, p in self.social_patterns.items()})
        sentiment = self.sentiment_analyzer.polarity_scores(original_text)
        features.update({f'sentiment_{k}': v for k, v in sentiment.items()})
        return features

    def clean_text(self, text):
        text = str(text)
        text = contractions.fix(text)
        text = emoji.demojize(text, delimiters=(" ", " "))
        text = text.lower()
        text = re.sub(self.social_patterns['url'], '[URL]', text)
        text = re.sub(self.social_patterns['mention'], '[MENTION]', text)
        text = re.sub(r'#(\w+)', r'hashtag \1', text)
        return re.sub(r'\s+', ' ', text).strip()

    def preprocess_dataset(self, df):
        print("\nExtracting comprehensive features...")
        feature_data = df['text'].apply(self.extract_comprehensive_features)
        feature_df = pd.DataFrame(list(feature_data))
        df['cleaned_text'] = df['text'].apply(self.clean_text)
        df_processed = pd.concat([df.reset_index(drop=True), feature_df.reset_index(drop=True)], axis=1)
        print("âœ… Preprocessing completed!")
        return df_processed

# ==============================================================================
# 3. Multi-Model Training Class
# ==============================================================================
class MultiModelAbusiveDetector:
    """Manages the training and evaluation of multiple detection models."""
    def __init__(self):
        self.models = {}
        self.vectorizers = {}
        self.label_encoder = LabelEncoder()
        self.feature_columns = None
        self.results = {}

    def prepare_data(self, df_proc):
        # Dynamically get feature columns, excluding identifiers and text fields
        self.feature_columns = [col for col in df_proc.columns if col not in ['text', 'label', 'subcategory', 'cleaned_text', 'encoded_label']]
        for col in self.feature_columns:
            df_proc[col] = pd.to_numeric(df_proc[col], errors='coerce').fillna(0)
        df_proc['encoded_label'] = self.label_encoder.fit_transform(df_proc['label'])
        return df_proc

    def train_traditional_models(self, X_train_text, X_train_features, X_val_text, X_val_features, y_train, y_val):
        print("\nðŸ”„ Training traditional ML models...")
        self.vectorizers['tfidf'] = TfidfVectorizer(max_features=5000, stop_words='english', ngram_range=(1, 2))
        X_train_tfidf = self.vectorizers['tfidf'].fit_transform(X_train_text)
        X_val_tfidf = self.vectorizers['tfidf'].transform(X_val_text)
        X_train_combined = np.hstack([X_train_tfidf.toarray(), X_train_features])
        X_val_combined = np.hstack([X_val_tfidf.toarray(), X_val_features])

        models_to_train = {'Logistic Regression': LogisticRegression(random_state=42), 'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42), 'SVM': SVC(probability=True, random_state=42), 'Naive Bayes': MultinomialNB()}
        for name, model in models_to_train.items():
            print(f"Training {name}...")
            if name == 'Naive Bayes':
                model.fit(X_train_tfidf, y_train)
                pred = model.predict(X_val_tfidf)
            else:
                model.fit(X_train_combined, y_train)
                pred = model.predict(X_val_combined)
            acc, (p, r, f1, _) = accuracy_score(y_val, pred), precision_recall_fscore_support(y_val, pred, average='weighted', zero_division=0)
            self.models[name] = model
            self.results[name] = {'Accuracy': acc, 'Precision': p, 'Recall': r, 'F1-Score': f1}
            print(f"âœ… {name} - Accuracy: {acc:.4f}, F1: {f1:.4f}")

    def train_deep_learning_model(self, X_train_text, X_val_text, y_train, y_val, model_name='distilbert-base-uncased'):
        print("\nðŸ”„ Training transformer model...")
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(self.label_encoder.classes_))

        class SimpleDataset(Dataset):
            def __init__(self, texts, labels, tokenizer, max_length=128): self.texts, self.labels, self.tokenizer, self.max_length = texts, labels, tokenizer, max_length
            def __len__(self): return len(self.texts)
            def __getitem__(self, idx):
                encoding = self.tokenizer(str(self.texts[idx]), truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')
                return {'input_ids': encoding['input_ids'].flatten(), 'attention_mask': encoding['attention_mask'].flatten(), 'labels': torch.tensor(self.labels[idx], dtype=torch.long)}

        train_ds, val_ds = SimpleDataset(X_train_text, y_train, tokenizer), SimpleDataset(X_val_text, y_val, tokenizer)

        args = TrainingArguments(
            output_dir='./results',
            num_train_epochs=3,
            per_device_train_batch_size=16,
            logging_steps=50,
            eval_strategy="epoch",
            save_strategy="epoch",
            load_best_model_at_end=True,
            metric_for_best_model="f1",
            report_to="none"
        )

        def compute_metrics(p):
            preds = np.argmax(p.predictions, axis=1)
            acc, (prec, rec, f1, _) = accuracy_score(p.label_ids, preds), precision_recall_fscore_support(p.label_ids, preds, average='weighted', zero_division=0)
            return {'accuracy': acc, 'f1': f1, 'precision': prec, 'recall': rec}

        trainer = Trainer(model=model, args=args, train_dataset=train_ds, eval_dataset=val_ds, compute_metrics=compute_metrics, callbacks=[EarlyStoppingCallback(early_stopping_patience=1)])
        trainer.train()
        res = trainer.evaluate()
        self.models['Transformer'], self.results['Transformer'] = trainer, {'Accuracy': res['eval_accuracy'], 'Precision': res['eval_precision'], 'Recall': res['eval_recall'], 'F1-Score': res['eval_f1']}
        print(f"âœ… Transformer - Accuracy: {res['eval_accuracy']:.4f}, F1: {res['eval_f1']:.4f}")

    def get_model_comparison(self):
        return pd.DataFrame(self.results).T.sort_values('F1-Score', ascending=False)

# ==============================================================================
# 4. Main Execution Pipeline
# ==============================================================================

# Step 1: Generate the raw dataset
print("--- Step 1: Generating Synthetic Dataset ---")
generator = AbusiveMessageDatasetGenerator()
df = generator.create_comprehensive_dataset()
print(f"Dataset created with {len(df)} samples.")

# Step 2: Preprocess data and engineer features
print("\n--- Step 2: Preprocessing and Feature Engineering ---")
preprocessor = AdvancedAbusiveTextPreprocessor()
df_processed = preprocessor.preprocess_dataset(df)

# Step 3: Prepare data for modeling
print("\n--- Step 3: Preparing Data for Models ---")
detector = MultiModelAbusiveDetector()
df_prepared = detector.prepare_data(df_processed)

# Step 4: Split data into training, validation, and test sets
print("\n--- Step 4: Splitting Data ---")
X_text = df_prepared['cleaned_text'].values
X_features = df_prepared[detector.feature_columns].values
y = df_prepared['encoded_label'].values

# Create a main train/test split (80/20)
X_train_text, X_test_text, X_train_features, X_test_features, y_train, y_test = train_test_split(
    X_text, X_features, y, test_size=0.2, random_state=42, stratify=y)

# Create a train/validation split from the main training set (80/20 of the 80%)
X_train_split_text, X_val_text, X_train_split_features, X_val_features, y_train_split, y_val = train_test_split(
    X_train_text, X_train_features, y_train, test_size=0.2, random_state=42, stratify=y_train)
print("Data successfully split into training, validation, and test sets.")

# Step 5: Train all models
print("\n--- Step 5: Model Training ---")
detector.train_traditional_models(X_train_split_text, X_train_split_features, X_val_text, X_val_features, y_train_split, y_val)
detector.train_deep_learning_model(X_train_split_text, X_val_text, y_train_split, y_val)

# Step 6: Display model comparison
print("\n--- Final Results: Model Performance Comparison (on Validation Set) ---")
comparison_df = detector.get_model_comparison()
print(comparison_df.to_string())


# ==============================================================================
# 5. Interactive Social Media Analyzer (using public pre-trained models)
# ==============================================================================
print("\n" + "="*60)
print("ðŸš€ Setting up Interactive Social Media Analyzer...")
print("="*60)

# We use public, pre-trained models for this interactive part for simplicity and robustness.
def load_analyzer_models():
    global abuse_tokenizer, abuse_model, fakenews_tokenizer, fakenews_model
    print("Loading public AI models for interactive analysis...")
    abuse_tokenizer = AutoTokenizer.from_pretrained("unitary/toxic-bert")
    abuse_model = AutoModelForSequenceClassification.from_pretrained("unitary/toxic-bert")
    fakenews_tokenizer = AutoTokenizer.from_pretrained("twhug/fake-news-bert-tiny")
    fakenews_model = AutoModelForSequenceClassification.from_pretrained("twhug/fake-news-bert-tiny")
    print("âœ… Public models loaded and ready.")

def analyze_text(text_to_analyze):
    if text_to_analyze and text_to_analyze.strip():
        print(f"\nðŸ’¬ Analyzing Post: \"{text_to_analyze}\"\n")

        # --- Fake News Analysis ---
        print("-" * 50)
        print("## ðŸ“° Fake News Analysis")
        inputs_news = fakenews_tokenizer(text_to_analyze, return_tensors="pt", truncation=True, padding=True, max_length=512)
        with torch.no_grad():
            logits_news = fakenews_model(**inputs_news).logits
        conf, pred_id = torch.max(F.softmax(logits_news, dim=1), dim=1)
        news_label, news_conf = fakenews_model.config.id2label[pred_id.item()], conf.item()
        verdict = "FAKE âŒ" if news_label.upper() == 'FAKE' else "REAL âœ…"
        print(f"**Verdict: Likely {verdict}** (Confidence: {news_conf:.2%})")

        # --- Abusive Language Analysis ---
        print("\n" + "-" * 50)
        print("## ðŸ˜  Abusive Language Analysis")
        inputs_abuse = abuse_tokenizer(text_to_analyze, return_tensors="pt", truncation=True, padding=True, max_length=512)
        with torch.no_grad():
            logits_abuse = abuse_model(**inputs_abuse).logits
        abuse_scores = {abuse_model.config.id2label[i]: s.item() for i, s in enumerate(torch.sigmoid(logits_abuse)[0])}
        if abuse_scores.get('toxic', 0) > 0.5:
            print("**Verdict: Contains potentially abusive language.**")
            for label, score in sorted(abuse_scores.items(), key=lambda item: item[1], reverse=True):
                if score > 0.1: print(f"  - {label.replace('_', ' ').capitalize()}: {score:.2%}")
        else:
            print("**Verdict: Does not appear to contain abusive language.**")
        print("=" * 50)
    else:
        print("Please enter text in the form above and run the cell again.")

# Load models only once
if 'abuse_model' not in globals():
    load_analyzer_models()

#@title ðŸ“° Social Media News & Abuse Analyzer
#@markdown ### ðŸ‘‡ Enter text to analyze here, then run the cell:
text_to_analyze = "BREAKING: Scientists announce they have discovered a new planet made entirely of diamond." #@param {type:"string"}
#@markdown ---
analyze_text(text_to_analyze)

# -*- coding: utf-8 -*-
"""
Corrected and Combined Abusive Content Detection and Analysis Script.
"""

# Install required packages for Google Colab
!pip install transformers torch scikit-learn pandas numpy matplotlib seaborn nltk wordcloud -q
!pip install datasets accelerate plotly textstat vaderSentiment -q
!pip install -q contractions emoji sentencepiece -q

# --- Core Imports ---
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
import re
import string
import warnings
import os
from datetime import datetime
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# --- NLP and ML Imports ---
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize, sent_tokenize
from nltk.stem import WordNetLemmatizer
from nltk.sentiment.vader import SentimentIntensityAnalyzer
import contractions
import emoji
import textstat

# --- Transformers and Deep Learning ---
from transformers import (
    AutoTokenizer, AutoModelForSequenceClassification,
    TrainingArguments, Trainer, EarlyStoppingCallback
)
import torch.nn.functional as F


# --- Scikit-learn ---
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    accuracy_score, precision_recall_fscore_support,
    classification_report, confusion_matrix
)
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.naive_bayes import MultinomialNB

# --- Global Settings ---
warnings.filterwarnings('ignore')

# Download NLTK data quietly
nltk.download('stopwords', quiet=True)
nltk.download('punkt', quiet=True)
nltk.download('vader_lexicon', quiet=True)
nltk.download('wordnet', quiet=True)
nltk.download('omw-1.4', quiet=True)

print("âœ… All packages installed and data downloaded successfully!")

# ==============================================================================
# 1. Dataset Generation Class
# ==============================================================================

class AbusiveMessageDatasetGenerator:
    """Generate comprehensive abusive message dataset with multiple categories and patterns."""

    def create_comprehensive_dataset(self):
        """Create a realistic and diverse dataset for abusive message detection."""
        direct_insults = [
            "You're absolutely pathetic and worthless, nobody could ever love someone like you", "Shut up you stupid idiot, your opinion doesn't matter to anyone",
            "You're so dumb it's actually painful to read your comments", "What a complete loser, get a life and stop embarrassing yourself",
            "You're ugly inside and out, no wonder you have no friends", "Stop being such a crybaby and grow up already",
            "Your parents must be so disappointed in how you turned out", "You're a waste of space and oxygen, the world would be better without you",
            "How can someone be this stupid? It's actually impressive", "You're nothing but a pathetic attention seeker"
        ]
        cyberbullying = [
            "I'm going to make sure everyone knows what a fraud you are", "You better watch your back because I know where you live",
            "I'm going to ruin your reputation and make your life miserable", "Everyone at school is laughing at you behind your back",
            "You think you're safe online but I know who you really are", "I'm going to post this embarrassing photo everywhere",
            "Nobody likes you and they're all just pretending to be nice", "You're going to regret crossing me, I promise you that",
            "I'm going to make sure you lose your job over this", "You have no idea what I'm capable of doing to you"
        ]
        hate_speech = [
            "People like you don't belong in this country and should go back where you came from", "Your entire race is nothing but criminals and parasites",
            "Women are too emotional and stupid to make important decisions", "All immigrants are stealing jobs from real Americans",
            "People of your religion are all terrorists and extremists", "Disabled people are just a burden on society",
            "LGBTQ+ people are mentally ill and need to be fixed", "Poor people are just lazy and deserve their situation",
            "Your culture is backwards and inferior to ours", "Old people should just die and stop wasting resources"
        ]
        threats = [
            "I'm going to beat you up so badly you'll end up in the hospital", "You better sleep with one eye open tonight",
            "I know where you work and I'm coming for you", "Someone should put you out of your misery permanently",
            "I'm going to destroy everything you care about", "You're going to pay for what you said, I guarantee it",
            "I have friends who would love to teach you a lesson", "You won't be laughing when something bad happens to you",
            "I'm going to make you regret the day you were born", "Your family better watch out too"
        ]
        harassment = [
            "Hey baby, why don't you show me what's under those clothes", "I bet you're just asking for it dressed like that",
            "You should feel lucky that someone like me is interested in you", "I know what you really want and I'm going to give it to you",
            "Stop playing hard to get, we both know you want this", "Your body belongs to men like me whether you like it or not",
            "I'm going to make you mine whether you want it or not", "You exist for my pleasure and entertainment",
            "I don't care if you say no, I'm going to take what I want", "Women like you are only good for one thing"
        ]
        discriminatory = [
            "People with disabilities are just pretending to get special treatment", "Mental illness is just an excuse for weak people",
            "Single mothers are all welfare queens who chose bad men", "Homeless people choose to be on the streets because they're lazy",
            "Refugees are just economic migrants trying to take advantage", "Young people today are all entitled snowflakes",
            "Older workers are useless and should be forced to retire", "People who speak different languages should learn English or leave",
            "Alternative lifestyles are corrupting our children and society", "Traditional values are under attack by liberal extremists"
        ]
        casual_conversation = [
            "Hey everyone! Hope you're all having a great day today", "Just finished watching an amazing movie, highly recommend it",
            "Anyone know a good restaurant in downtown? Looking for suggestions", "Thanks for all the birthday wishes, you guys are awesome",
            "Just got back from vacation and feeling refreshed and happy", "Working from home today, anyone else enjoying the flexibility?",
            "The weather is perfect for a walk in the park this afternoon", "Great job on the presentation yesterday, very impressive work",
            "Looking forward to the weekend, any fun plans everyone?", "Coffee tastes extra good this morning, ready to tackle Monday"
        ]
        positive_messages = [
            "You're doing amazing and should be proud of your accomplishments", "Thanks for always being such a supportive and caring friend",
            "Your hard work and dedication really inspire me every day", "I believe in you and know you can overcome any challenge",
            "You have such a positive impact on everyone around you", "Keep up the excellent work, you're making a real difference",
            "Your creativity and talent never cease to amaze me", "Thank you for being such a wonderful part of our community",
            "You handled that difficult situation with grace and wisdom", "I'm grateful to have someone like you in my life"
        ]
        neutral_content = [
            "The city council meeting is scheduled for Thursday at 7 PM", "Public transportation schedules have been updated on the website",
            "The library will be closed next Monday for maintenance work", "New parking regulations go into effect starting next month",
            "Weather forecast shows rain expected throughout the weekend", "The community center is offering free computer classes",
            "Local farmers market is open every Saturday from 8 AM to 2 PM", "Registration for summer programs begins on the first of May",
            "The annual festival has been moved to the downtown park", "Please remember to recycle and help keep our environment clean"
        ]
        informative = [
            "Did you know that reading regularly can improve memory and cognitive function?", "Regular exercise has been shown to reduce stress and improve mental health",
            "Learning a new language can enhance brain plasticity and problem-solving skills", "Volunteering in your community can provide a sense of purpose and fulfillment",
            "Eating a balanced diet with plenty of fruits and vegetables supports overall health", "Getting adequate sleep is crucial for immune system function and emotional regulation",
            "Meditation and mindfulness practices can help reduce anxiety and improve focus", "Building strong relationships contributes significantly to happiness and well-being",
            "Spending time in nature has been linked to reduced stress and improved mood", "Continuous learning and skill development can lead to career advancement opportunities"
        ]

        abusive_messages = direct_insults + cyberbullying + hate_speech + threats + harassment + discriminatory
        normal_messages = casual_conversation + positive_messages + neutral_content + informative
        all_texts = abusive_messages + normal_messages
        all_labels = ['abusive'] * len(abusive_messages) + ['normal'] * len(normal_messages)
        subcategories = (['direct_insults'] * len(direct_insults) + ['cyberbullying'] * len(cyberbullying) +
                         ['hate_speech'] * len(hate_speech) + ['threats'] * len(threats) +
                         ['harassment'] * len(harassment) + ['discriminatory'] * len(discriminatory) +
                         ['normal'] * len(normal_messages))

        engagement_data, user_data = [], []
        for label in all_labels:
            if label == 'abusive':
                engagement = {'likes': np.random.randint(0, 20), 'shares': np.random.randint(0, 5), 'comments': np.random.randint(5, 50), 'reports': np.random.randint(1, 10)}
                user_profile = {'account_age_days': np.random.randint(1, 365), 'follower_count': np.random.randint(10, 1000), 'following_count': np.random.randint(100, 5000), 'post_frequency': np.random.randint(5, 50), 'verified': np.random.choice([True, False], p=[0.1, 0.9])}
            else:
                engagement = {'likes': np.random.randint(5, 100), 'shares': np.random.randint(1, 20), 'comments': np.random.randint(0, 30), 'reports': np.random.randint(0, 2)}
                user_profile = {'account_age_days': np.random.randint(30, 2000), 'follower_count': np.random.randint(50, 5000), 'following_count': np.random.randint(50, 2000), 'post_frequency': np.random.randint(1, 20), 'verified': np.random.choice([True, False], p=[0.3, 0.7])}
            engagement_data.append(engagement)
            user_data.append(user_profile)

        return pd.DataFrame({
            'text': all_texts, 'label': all_labels, 'subcategory': subcategories,
            'platform': np.random.choice(['Twitter', 'Facebook', 'Instagram', 'TikTok', 'Reddit'], len(all_texts)),
            'timestamp': pd.to_datetime(pd.Series(pd.date_range(start='2024-01-01', periods=len(all_texts), freq='H'))),
            'likes': [eng['likes'] for eng in engagement_data], 'shares': [eng['shares'] for eng in engagement_data],
            'comments': [eng['comments'] for eng in engagement_data], 'reports': [eng['reports'] for eng in engagement_data],
            'account_age_days': [user['account_age_days'] for user in user_data], 'follower_count': [user['follower_count'] for user in user_data],
            'following_count': [user['following_count'] for user in user_data], 'post_frequency': [user['post_frequency'] for user in user_data],
            'verified': [user['verified'] for user in user_data]
        })

# ==============================================================================
# 2. Text Preprocessing Class
# ==============================================================================

class AdvancedAbusiveTextPreprocessor:
    def __init__(self):
        self.stop_words = set(stopwords.words('english'))
        self.lemmatizer = WordNetLemmatizer()
        self.sentiment_analyzer = SentimentIntensityAnalyzer()
        self.profanity_words = {'mild': ['damn', 'hell', 'crap', 'stupid', 'idiot'], 'moderate': ['hate', 'kill', 'die', 'ugly', 'loser'], 'severe': ['threat_word', 'violence_word']}
        self.intensity_words = ['extremely', 'totally', 'absolutely', 'really', 'very']
        self.emotional_words = {'anger': ['angry', 'furious', 'rage'], 'disgust': ['disgusting', 'revolting', 'nasty'], 'fear': ['scared', 'terrified', 'afraid'], 'sadness': ['sad', 'depressed', 'miserable']}
        self.social_patterns = {'all_caps': r'[A-Z]{3,}', 'repeated_chars': r'(.)\1{2,}', 'excessive_punctuation': r'[!?]{2,}', 'mention': r'@\w+', 'hashtag': r'#\w+', 'url': r'http[s]?://\S+'}

    def extract_comprehensive_features(self, text):
        original_text = str(text)
        words = original_text.lower().split()
        features = {'char_count': len(original_text), 'word_count': len(words), 'sentence_count': len(sent_tokenize(original_text)), 'avg_word_length': np.mean([len(w) for w in words] or [0])}
        features.update({'flesch_reading_ease': textstat.flesch_reading_ease(original_text), 'flesch_kincaid_grade': textstat.flesch_kincaid_grade(original_text), 'automated_readability_index': textstat.automated_readability_index(original_text)})
        features.update({'exclamation_count': original_text.count('!'), 'question_count': original_text.count('?'), 'caps_ratio': sum(1 for c in original_text if c.isupper()) / len(original_text) if original_text else 0})
        features.update({p_name: len(re.findall(p, original_text)) for p_name, p in self.social_patterns.items()})
        profanity_scores = {f'{level}_profanity_count': sum(1 for w in words if w in lst) for level, lst in self.profanity_words.items()}
        features.update(profanity_scores)
        features['total_profanity_score'] = sum(profanity_scores.values())
        features['intensity_word_count'] = sum(1 for w in words if w in self.intensity_words)
        features.update({f'{emotion}_word_count': sum(1 for w in words if w in lst) for emotion, lst in self.emotional_words.items()})
        sentiment = self.sentiment_analyzer.polarity_scores(original_text)
        features.update({f'sentiment_{k}': v for k, v in sentiment.items()})
        return features

    def clean_text(self, text):
        text = str(text)
        text = contractions.fix(text)
        text = emoji.demojize(text)
        text = text.lower()
        text = re.sub(self.social_patterns['url'], '[URL]', text)
        text = re.sub(self.social_patterns['mention'], '[MENTION]', text)
        text = re.sub(r'#(\w+)', r'hashtag_\1', text)
        return re.sub(r'\s+', ' ', text).strip()

    def preprocess_dataset(self, df):
        print("\nExtracting comprehensive features...")
        feature_data = df['text'].apply(self.extract_comprehensive_features)
        feature_df = pd.DataFrame(list(feature_data))
        df['cleaned_text'] = df['text'].apply(self.clean_text)
        df_processed = pd.concat([df.reset_index(drop=True), feature_df.reset_index(drop=True)], axis=1)
        print("âœ… Preprocessing completed!")
        return df_processed

# ==============================================================================
# 3. Multi-Model Training Class
# ==============================================================================

class MultiModelAbusiveDetector:
    def __init__(self):
        self.models = {}
        self.vectorizers = {}
        self.label_encoder = LabelEncoder()
        self.feature_columns = None
        self.results = {}

    def prepare_data(self, df_proc):
        self.feature_columns = [col for col in df_proc.columns if col not in ['text', 'label', 'subcategory', 'platform', 'timestamp', 'cleaned_text', 'encoded_label']]
        for col in self.feature_columns:
            df_proc[col] = pd.to_numeric(df_proc[col], errors='coerce').fillna(0)
        df_proc['encoded_label'] = self.label_encoder.fit_transform(df_proc['label'])
        return df_proc

    def train_traditional_models(self, X_train_text, X_train_features, X_val_text, X_val_features, y_train, y_val):
        print("\nðŸ”„ Training traditional ML models...")
        self.vectorizers['tfidf'] = TfidfVectorizer(max_features=5000, stop_words='english', ngram_range=(1, 2))
        X_train_tfidf = self.vectorizers['tfidf'].fit_transform(X_train_text)
        X_val_tfidf = self.vectorizers['tfidf'].transform(X_val_text)
        X_train_combined = np.hstack([X_train_tfidf.toarray(), X_train_features])
        X_val_combined = np.hstack([X_val_tfidf.toarray(), X_val_features])

        models_to_train = {'logistic_regression': LogisticRegression(random_state=42), 'random_forest': RandomForestClassifier(n_estimators=100, random_state=42), 'svm': SVC(probability=True, random_state=42), 'naive_bayes': MultinomialNB()}
        for name, model in models_to_train.items():
            print(f"Training {name}...")
            if name == 'naive_bayes': model.fit(X_train_tfidf, y_train); pred = model.predict(X_val_tfidf)
            else: model.fit(X_train_combined, y_train); pred = model.predict(X_val_combined)
            acc, (p, r, f1, _) = accuracy_score(y_val, pred), precision_recall_fscore_support(y_val, pred, average='weighted')
            self.models[name] = model
            self.results[name] = {'accuracy': acc, 'precision': p, 'recall': r, 'f1': f1}
            print(f"âœ… {name.replace('_', ' ').title()} - Accuracy: {acc:.4f}, F1: {f1:.4f}")

    def train_deep_learning_model(self, X_train_text, X_val_text, y_train, y_val, model_name='distilbert-base-uncased'):
        print("\nðŸ”„ Training transformer model...")
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(self.label_encoder.classes_))

        class SimpleDataset(Dataset):
            def __init__(self, texts, labels, tokenizer, max_length=128): self.texts, self.labels, self.tokenizer, self.max_length = texts, labels, tokenizer, max_length
            def __len__(self): return len(self.texts)
            def __getitem__(self, idx):
                encoding = self.tokenizer(str(self.texts[idx]), truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')
                return {'input_ids': encoding['input_ids'].flatten(), 'attention_mask': encoding['attention_mask'].flatten(), 'labels': torch.tensor(self.labels[idx], dtype=torch.long)}

        train_dataset, val_dataset = SimpleDataset(X_train_text, y_train, tokenizer), SimpleDataset(X_val_text, y_val, tokenizer)
        args = TrainingArguments(output_dir='./results', num_train_epochs=3, per_device_train_batch_size=16, logging_steps=50, evaluation_strategy="epoch", save_strategy="epoch", load_best_model_at_end=True, metric_for_best_model="f1", report_to="none")
        def compute_metrics(p):
            preds = np.argmax(p.predictions, axis=1)
            acc, (prec, rec, f1, _) = accuracy_score(p.label_ids, preds), precision_recall_fscore_support(p.label_ids, preds, average='weighted')
            return {'accuracy': acc, 'f1': f1, 'precision': prec, 'recall': rec}
        trainer = Trainer(model=model, args=args, train_dataset=train_dataset, eval_dataset=val_dataset, compute_metrics=compute_metrics, callbacks=[EarlyStoppingCallback(early_stopping_patience=1)])
        trainer.train()
        res = trainer.evaluate()
        self.models['transformer'], self.results['transformer'] = trainer, {'accuracy': res['eval_accuracy'], 'precision': res['eval_precision'], 'recall': res['eval_recall'], 'f1': res['eval_f1']}
        print(f"âœ… Transformer - Accuracy: {res['eval_accuracy']:.4f}, F1: {res['eval_f1']:.4f}")

    def get_model_comparison(self):
        return pd.DataFrame(self.results.values(), index=self.results.keys()).rename(columns=str.capitalize).sort_values('F1', ascending=False)

# ==============================================================================
# 4. Main Execution Pipeline
# ==============================================================================

# Step 1: Generate the raw dataset
print("\n--- Starting Step 1: Dataset Generation ---")
generator = AbusiveMessageDatasetGenerator()
df = generator.create_comprehensive_dataset()
print(f"Dataset created with {len(df)} samples.")

# Step 2: Preprocess the data and engineer features
# THIS IS THE CRITICAL FIX: Create df_processed *before* using it.
print("\n--- Starting Step 2: Preprocessing and Feature Engineering ---")
preprocessor = AdvancedAbusiveTextPreprocessor()
df_processed = preprocessor.preprocess_dataset(df)

# Step 3: Prepare data for modeling and split into sets
print("\n--- Starting Step 3: Data Preparation and Splitting ---")
detector = MultiModelAbusiveDetector()
df_prepared = detector.prepare_data(df_processed)

X_text = df_prepared['cleaned_text'].values
X_features = df_prepared[detector.feature_columns].values
y = df_prepared['encoded_label'].values

X_train_text, X_test_text, X_train_features, X_test_features, y_train, y_test = train_test_split(
    X_text, X_features, y, test_size=0.2, random_state=42, stratify=y)
X_train_split_text, X_val_text, X_train_split_features, X_val_features, y_train_split, y_val = train_test_split(
    X_train_text, X_train_features, y_train, test_size=0.2, random_state=42, stratify=y_train)
print("Data successfully split into training, validation, and test sets.")

# Step 4: Train all models
print("\n--- Starting Step 4: Model Training ---")
detector.train_traditional_models(X_train_split_text, X_train_split_features, X_val_text, X_val_features, y_train_split, y_val)
detector.train_deep_learning_model(X_train_split_text, X_val_text, y_train_split, y_val)

# Step 5: Display model comparison
print("\n--- Final Results: Model Performance Comparison (on Validation Set) ---")
comparison_df = detector.get_model_comparison()
print(comparison_df.to_string())


# ==============================================================================
# 5. Interactive Social Media Analyzer
# ==============================================================================
print("\n" + "="*60)
print("ðŸš€ Setting up Interactive Social Media Analyzer...")
print("="*60)

# We use public, pre-trained models for this interactive part for simplicity.
def load_analyzer_models():
    global abuse_tokenizer, abuse_model, fakenews_tokenizer, fakenews_model
    print("\nLoading public AI models for interactive analysis...")
    abuse_tokenizer = AutoTokenizer.from_pretrained("unitary/toxic-bert")
    abuse_model = AutoModelForSequenceClassification.from_pretrained("unitary/toxic-bert")
    fakenews_tokenizer = AutoTokenizer.from_pretrained("twhug/fake-news-bert-tiny")
    fakenews_model = AutoModelForSequenceClassification.from_pretrained("twhug/fake-news-bert-tiny")
    print("âœ… Public models loaded.")

def detect_abuse(text):
    inputs = abuse_tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=512)
    with torch.no_grad():
        logits = abuse_model(**inputs).logits
    return {abuse_model.config.id2label[i]: prob.item() for i, prob in enumerate(torch.sigmoid(logits)[0])}

def detect_fake_news(text):
    inputs = fakenews_tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=512)
    with torch.no_grad():
        logits = fakenews_model(**inputs).logits
    probabilities = F.softmax(logits, dim=1)
    conf, pred_id = torch.max(probabilities, dim=1)
    return fakenews_model.config.id2label[pred_id.item()], conf.item()

# Load models only once
if 'abuse_model' not in globals():
    load_analyzer_models()

#@title ðŸ“° Social Media News & Abuse Analyzer
#@markdown ### ðŸ‘‡ Enter text to analyze here:
text_to_analyze = "BREAKING: Scientists announce they have discovered a new planet made entirely of diamond." #@param {type:"string"}
#@markdown ---
if text_to_analyze.strip():
    print(f"\nðŸ’¬ Analyzing Post: \"{text_to_analyze}\"\n")
    print("-" * 50)
    news_label, news_confidence = detect_fake_news(text_to_analyze)
    print(f"## ðŸ“° Fake News Analysis")
    verdict = "FAKE âŒ" if news_label.upper() == 'FAKE' else "REAL âœ…"
    print(f"**Verdict: Likely {verdict}** (Confidence: {news_confidence:.2%})")
    print("-" * 50)
    abuse_scores = detect_abuse(text_to_analyze)
    print("## ðŸ˜  Abusive Language Analysis")
    if abuse_scores.get('toxic', 0) > 0.5:
        print("**Verdict: Contains potentially abusive language.**")
        for label, score in sorted(abuse_scores.items(), key=lambda item: item[1], reverse=True):
            if score > 0.1: print(f"  - {label.replace('_', ' ').capitalize()}: {score:.2%}")
    else:
        print("**Verdict: Does not appear to contain abusive language.**")
    print("=" * 50)
else:
    print("Please enter text in the form above and run the cell again.")



import nltk
nltk.download('punkt_tab')

class AdvancedAbusiveTextPreprocessor:


    def __init__(self):
        self.stop_words = set(stopwords.words('english'))
        self.lemmatizer = WordNetLemmatizer()
        self.stemmer = PorterStemmer()
        self.sentiment_analyzer = SentimentIntensityAnalyzer()


        self.profanity_words = {
            'mild': ['damn', 'hell', 'crap', 'stupid', 'idiot', 'moron', 'jerk'],
            'moderate': ['hate', 'kill', 'die', 'ugly', 'loser', 'pathetic', 'worthless'],
            'severe': ['threat_word', 'violence_word', 'extreme_profanity']
        }


        self.intensity_words = [
            'extremely', 'totally', 'completely', 'absolutely', 'really', 'very',
            'super', 'ultra', 'mega', 'so', 'too', 'quite', 'rather'
        ]


        self.emotional_words = {
            'anger': ['angry', 'furious', 'rage', 'mad', 'pissed', 'livid'],
            'disgust': ['disgusting', 'revolting', 'sick', 'gross', 'nasty'],
            'fear': ['scared', 'terrified', 'afraid', 'worried', 'anxious'],
            'sadness': ['sad', 'depressed', 'miserable', 'unhappy', 'crying']
        }


        self.social_patterns = {
            'all_caps': r'[A-Z]{3,}',
            'repeated_chars': r'(.)\1{2,}',
            'excessive_punctuation': r'[!?]{2,}',
            'mention_pattern': r'@\w+',
            'hashtag_pattern': r'#\w+',
            'url_pattern': r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',
            'emoji_pattern': r'[\U0001f600-\U0001f64f\U0001f300-\U0001f5ff\U0001f680-\U0001f6ff\U0001f1e0-\U0001f1ff]'
        }

    def extract_comprehensive_features(self, text):


        original_text = str(text)
        text_lower = original_text.lower()


        features = {
            'char_count': len(original_text),
            'word_count': len(original_text.split()),
            'sentence_count': len(sent_tokenize(original_text)),
            'avg_word_length': np.mean([len(word) for word in original_text.split()]) if original_text.split() else 0,
            'unique_word_ratio': len(set(original_text.split())) / len(original_text.split()) if original_text.split() else 0
        }


        features.update({
            'flesch_reading_ease': textstat.flesch_reading_ease(original_text),
            'flesch_kincaid_grade': textstat.flesch_kincaid_grade(original_text),
            'automated_readability_index': textstat.automated_readability_index(original_text)
        })


        features.update({
            'exclamation_count': original_text.count('!'),
            'question_count': original_text.count('?'),
            'caps_ratio': sum(1 for c in original_text if c.isupper()) / len(original_text) if original_text else 0,
            'digit_ratio': sum(1 for c in original_text if c.isdigit()) / len(original_text) if original_text else 0,
            'punctuation_ratio': sum(1 for c in original_text if c in string.punctuation) / len(original_text) if original_text else 0
        })


        features.update({
            'all_caps_words': len(re.findall(self.social_patterns['all_caps'], original_text)),
            'repeated_chars': len(re.findall(self.social_patterns['repeated_chars'], original_text)),
            'excessive_punctuation': len(re.findall(self.social_patterns['excessive_punctuation'], original_text)),
            'mention_count': len(re.findall(self.social_patterns['mention_pattern'], original_text)),
            'hashtag_count': len(re.findall(self.social_patterns['hashtag_pattern'], original_text)),
            'url_count': len(re.findall(self.social_patterns['url_pattern'], original_text)),
            'emoji_count': len(re.findall(self.social_patterns['emoji_pattern'], original_text))
        })


        profanity_scores = {'mild': 0, 'moderate': 0, 'severe': 0}
        words = text_lower.split()
        for word in words:
            for level, word_list in self.profanity_words.items():
                if any(prof_word in word for prof_word in word_list):
                    profanity_scores[level] += 1

        features.update({
            'mild_profanity_count': profanity_scores['mild'],
            'moderate_profanity_count': profanity_scores['moderate'],
            'severe_profanity_count': profanity_scores['severe'],
            'total_profanity_score': sum(profanity_scores.values())
        })


        intensity_count = sum(1 for word in words if word in self.intensity_words)
        features['intensity_word_count'] = intensity_count

        for emotion, word_list in self.emotional_words.items():
            emotion_count = sum(1 for word in words if word in word_list)
            features[f'{emotion}_word_count'] = emotion_count


        sentiment_scores = self.sentiment_analyzer.polarity_scores(original_text)
        features.update({
            'sentiment_negative': sentiment_scores['neg'],
            'sentiment_neutral': sentiment_scores['neu'],
            'sentiment_positive': sentiment_scores['pos'],
            'sentiment_compound': sentiment_scores['compound']
        })


        personal_pronouns = ['you', 'your', 'yourself', 'yours']
        features['personal_pronoun_count'] = sum(1 for word in words if word in personal_pronouns)


        threat_words = ['kill', 'hurt', 'destroy', 'ruin', 'beat', 'attack', 'revenge', 'payback']
        features['threat_word_count'] = sum(1 for word in words if word in threat_words)

        return features

    def clean_text(self, text):
        """Clean and normalize text while preserving important abuse indicators"""

        text = str(text)


        text = contractions.fix(text)


        text = emoji.demojize(text)


        preserved_caps = re.findall(r'[A-Z]{3,}', text)
        preserved_repeated = re.findall(r'(.)\1{2,}', text)
        text = text.lower()
        text = re.sub(self.social_patterns['url_pattern'], '[URL]', text)
        text = re.sub(self.social_patterns['mention_pattern'], '[MENTION]', text)
        text = re.sub(self.social_patterns['hashtag_pattern'], lambda m: f"hashtag_{m.group(1)}", text)


        text = re.sub(r'(.)\1{3,}', r'\1\1', text)


        text = re.sub(r'[!]{2,}', '!!', text)
        text = re.sub(r'[?]{2,}', '??', text)


        text = re.sub(r'\s+', ' ', text).strip()

        return text

    def preprocess_dataset(self, df):
        """Apply preprocessing to entire dataset"""

        print("Extracting comprehensive features...")


        feature_data = df['text'].apply(self.extract_comprehensive_features)
        feature_df = pd.DataFrame(list(feature_data))


        df['cleaned_text'] = df['text'].apply(self.clean_text)


        df_processed = pd.concat([df, feature_df], axis=1)

        print(" Preprocessing completed!")
        return df_processed


print("Starting advanced text preprocessing...")
preprocessor = AdvancedAbusiveTextPreprocessor()
df_processed = preprocessor.preprocess_dataset(df)

print("Sample processed data:")
sample_idx = df_processed[df_processed['label'] == 'abusive'].index[0]
print(f"Original: {df_processed.loc[sample_idx, 'text']}")
print(f"Cleaned: {df_processed.loc[sample_idx, 'cleaned_text']}")
print(f"Features: char_count={df_processed.loc[sample_idx, 'char_count']}, "
      f"profanity_score={df_processed.loc[sample_idx, 'total_profanity_score']}, "
      f"sentiment_negative={df_processed.loc[sample_idx, 'sentiment_negative']:.3f}")

#@title ðŸ“° Social Media News & Abuse Analyzer
#@markdown 1. Run this cell. It will take a few minutes to set up the AI models the first time.
#@markdown 2. Enter any text (e.g., a news headline or comment) in the field below.
#@markdown 3. Run the cell again to see the analysis.
#@markdown ---
#@markdown ### ðŸ‘‡ Enter text to analyze here:
text_to_analyze = "BREAKING: Scientists announce they have discovered a new planet made entirely of diamond." #@param {type:"string"}
#@markdown ---

# Step 1: Install necessary libraries quietly
!pip install transformers sentencepiece -q

import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch.nn.functional as F
import warnings

# Suppress harmless warnings
warnings.filterwarnings("ignore")

# --- Model Loading Functions ---
def load_models():
    """Loads both the abuse detection and fake news detection models."""
    global abuse_tokenizer, abuse_model
    global fakenews_tokenizer, fakenews_model

    print("Loading AI models... This might take a few minutes.")
    # 1. Abuse Detection Model
    abuse_model_name = "unitary/toxic-bert"
    abuse_tokenizer = AutoTokenizer.from_pretrained(abuse_model_name)
    abuse_model = AutoModelForSequenceClassification.from_pretrained(abuse_model_name)
    print("âœ… Abuse Detector loaded.")

    # 2. Fake News Detection Model
    # Using a different model as the previous one was not accessible.
    fakenews_model_name = "twhug/fake-news-bert-tiny"
    fakenews_tokenizer = AutoTokenizer.from_pretrained(fakenews_model_name)
    fakenews_model = AutoModelForSequenceClassification.from_pretrained(fakenews_model_name)
    print("âœ… Fake News Detector loaded.")
    print("-" * 30)

# --- Analysis Functions ---
def detect_abuse(text):
    """Analyzes the text for abusive content and returns scores."""
    inputs = abuse_tokenizer(text, return_tensors="pt", truncation=True, padding=True)
    with torch.no_grad():
        logits = abuse_model(**inputs).logits
    probabilities = torch.sigmoid(logits)
    return {abuse_model.config.id2label[i]: prob.item() for i, prob in enumerate(probabilities[0])}

def detect_fake_news(text):
    """Analyzes the text for fake news and returns the verdict and confidence."""
    inputs = fakenews_tokenizer(text, return_tensors="pt", truncation=True, padding=True)
    with torch.no_grad():
        logits = fakenews_model(**inputs).logits
    probabilities = F.softmax(logits, dim=1)
    # The labels for this model are 'REAL' and 'FAKE'
    confidence, predicted_class_id = torch.max(probabilities, dim=1)
    predicted_label = fakenews_model.config.id2label[predicted_class_id.item()]
    return predicted_label, confidence.item()

# --- Main Workflow ---
if __name__ == "__main__":
    # Load models only once to save time on subsequent runs
    if 'abuse_model' not in globals():
        load_models()

    if text_to_analyze.strip():
        print(f"ðŸ’¬ Analyzing Post: \"{text_to_analyze}\"\n")
        print("="*50)

        # --- 1. Fake News Analysis ---
        print("## ðŸ“° Fake News Analysis")
        news_label, news_confidence = detect_fake_news(text_to_analyze)
        # Assuming the labels are 'REAL' and 'FAKE' and 'FAKE' is the second class (index 1)
        if news_label == 'FAKE':
             print(f"**Verdict: Likely FAKE News âŒ** (Confidence: {news_confidence:.2%})")
        else: # REAL or other labels if the model has them
            print(f"**Verdict: Likely REAL News âœ…** (Confidence: {news_confidence:.2%})")
        print("-" * 50)

        # --- 2. Abusive Language Analysis ---
        print("## ðŸ˜  Abusive Language Analysis")
        abuse_scores = detect_abuse(text_to_analyze)
        # Check if the primary 'toxic' score crosses a threshold
        if abuse_scores.get('toxic', 0) > 0.5: # Use .get to handle cases where 'toxic' label might be missing
            print("**Verdict: Contains abusive language.**")
            # Print significant abuse scores
            for label, score in abuse_scores.items():
                if score > 0.1: # Show labels with a score > 10%
                    print(f"  - {label.capitalize()}: {score:.2%}")
        else:
            print("**Verdict: Does not appear to contain abusive language.**")
        print("="*50)

    else:
        print("Please enter text in the form above and run again.")

# Commented out IPython magic to ensure Python compatibility.
# %env WANDB_DISABLED=true

"""**Please run the following cell to apply the correction and resolve the error.**"""

# ==============================================================================
# 1. SETUP: Install Necessary Libraries
# ==============================================================================
# We install the required Hugging Face libraries. The '-q' flag makes the
# installation less verbose.
!pip install transformers[torch] accelerate -q
!pip install datasets scikit-learn pandas -q

#  IMPORTANT: After this cell finishes, please restart the runtime.
# You can do this by going to the menu and clicking:
# Runtime -> Restart runtime
# This ensures the new libraries are loaded correctly.


# ==============================================================================
# 2. IMPORTS: Bring in the Required Modules
# ==============================================================================
import pandas as pd
import numpy as np
import torch
from datasets import Dataset, DatasetDict
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_recall_fscore_support
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer,
)

# ==============================================================================
# 3. DATA PREPARATION: Create and Prepare the Dataset
# ==============================================================================
# For this self-contained example, we create our own dataset of social media comments.
# Labels: 0 = Not Abusive, 1 = Abusive
comments_data = {
    'text': [
        "This is amazing! Thanks for sharing this with us. â¤ï¸",
        "I completely agree with your point. Well said!",
        "You are a total idiot. I can't believe you'd post this.",
        "What a beautiful photo! Where was this taken?",
        "Go back to where you came from, you don't belong here.",
        "Such a stupid argument, you clearly know nothing.",
        "Thank you for the helpful tutorial.",
        "This is the worst product I have ever bought. A complete scam.",
        "I hate people who think like you.",
        "Have a great day everyone!",
        "Can't wait to see more from you!",
        "You are pathetic and your opinion is worthless.",
        "This is garbage. Delete your account.",
        "Lovely weather we're having today, isn't it?",
        "He's a loser and a clown.",
        "I learned so much from this post.",
        "You should be ashamed of yourself.",
        "I appreciate the effort you put into this.",
        "What an ignorant comment.",
        "Sending positive vibes your way! âœ¨"
    ],
    'label': [0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0]
}

# Convert the dictionary to a pandas DataFrame
df = pd.DataFrame(comments_data)

# Split the DataFrame into training and validation sets
train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])

# Convert pandas DataFrames to Hugging Face Dataset objects
train_dataset = Dataset.from_pandas(train_df)
val_dataset = Dataset.from_pandas(val_df)

# Combine them into a DatasetDict for easy handling
raw_datasets = DatasetDict({
    'train': train_dataset,
    'validation': val_dataset
})

print("âœ… Data prepared and split:")
print(raw_datasets)


# ==============================================================================
# 4. TOKENIZATION: Process Text for the Model
# ==============================================================================
# We use a pre-trained tokenizer from 'DistilBERT' to convert text to numbers.

MODEL_CHECKPOINT = 'distilbert-base-uncased'
tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)

# Create a function to tokenize the text in our dataset
def tokenize_function(examples):
    return tokenizer(examples['text'], padding='max_length', truncation=True)

# Apply the tokenization to our entire dataset
tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)

# Remove unneeded columns and set format to PyTorch tensors
tokenized_datasets = tokenized_datasets.remove_columns(['text', '__index_level_0__'])
tokenized_datasets.set_format('torch')

print("\n Data tokenized and ready for the model.")


# ==============================================================================
# 5. TRAINING: Fine-Tune the Model on Our Data
# ==============================================================================
# Load the pre-trained model with 2 labels for our binary classification task.
model = AutoModelForSequenceClassification.from_pretrained(MODEL_CHECKPOINT, num_labels=2)

# --- Define Metrics ---
# This function computes performance metrics during evaluation.
def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)
    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')
    acc = accuracy_score(labels, predictions)
    return {
        'accuracy': acc,
        'f1': f1,
        'precision': precision,
        'recall': recall
    }

# --- Define Training Arguments ---
# These arguments control the training loop.
training_args = TrainingArguments(
    output_dir="./results",
    learning_rate=2e-5,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=3,
    weight_decay=0.01,
    # evaluation_strategy="steps", # Removed this line
    # eval_steps=500, # Removed this line
    save_steps=500,
    warmup_steps=500,
)

# --- Initialize the Trainer ---
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_datasets['train'],
    eval_dataset=tokenized_datasets['validation'],
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
)

# --- Start Training! ---
print("\n Starting model training...")
trainer.train()
print("ðŸ Training complete!")


# ==============================================================================
# 6. EVALUATION: Check the Final Model Performance
# ==============================================================================
print("\n Evaluating model performance on the validation set...")
eval_results = trainer.evaluate()

print(f"\nAccuracy: {eval_results['eval_accuracy']:.4f}")
print(f"Precision: {eval_results['eval_precision']:.4f}")
print(f"Recall: {eval_results['eval_recall']:.4f}")
print(f"F1-Score: {eval_results['eval_f1']:.4f}")


# ==============================================================================
# 7. INFERENCE: Use the Trained Model for Predictions
# ==============================================================================
print("\n Testing the model with new sentences...")

# Put the model in evaluation mode
model.eval()

# Create a prediction pipeline
pipe = torch.nn.Sequential(
    model,
    torch.nn.Softmax(dim=-1)
)

# Define labels for our classes
labels = ['Not Abusive', 'Abusive']

# --- Sentences to test ---
test_sentences = [
    "You are doing a great job, keep it up!",
    "This is the ugliest thing I have ever seen.",
    "what a pathetic loser lol"
]

for sentence in test_sentences:
    inputs = tokenizer(sentence, return_tensors='pt', device=model.device)
    with torch.no_grad():
        logits = pipe(**inputs).squeeze()

    predicted_class_id = logits.argmax().item()
    confidence = logits[predicted_class_id].item()

    print(f"\nSentence: '{sentence}'")
    print(f"Verdict:  {labels[predicted_class_id]} (Confidence: {confidence:.2%})")

# Colab-ready script: Fine-tune a text classifier with LoRA (PEFT)
# Reads dataset from /mnt/data/labeled_data.csv (update path if needed)
# Supports binary, multi-class and multi-label setups (auto-detected)

# -------------- 1) Install required libraries (run this cell first) --------------
# NOTE: In Colab you may need to restart the runtime after installing some packages.
!pip install -q "transformers[torch]" accelerate datasets scikit-learn pandas peft evaluate

# -------------- 2) Imports --------------
import os
import pandas as pd
import numpy as np
import torch
from datasets import Dataset, DatasetDict
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MultiLabelBinarizer
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer,
    DataCollatorWithPadding,
)
from peft import LoraConfig, get_peft_model, PeftModel
from typing import List, Dict, Any

# -------------- 3) Configuration --------------
DATA_PATH = "/mnt/data/labeled_data.csv"  # change if your file is somewhere else
MODEL_CHECKPOINT = "roberta-base"  # feel free to change to distilbert-base-uncased etc.
OUTPUT_DIR = "./lora_results"
NUM_EPOCHS = 3
BATCH_SIZE = 8
LEARNING_RATE = 2e-5
SEED = 42

# -------------- 4) Utility: detect columns and prepare labels --------------

def load_and_inspect(path: str) -> pd.DataFrame:
    if not os.path.exists(path):
        raise FileNotFoundError(f"Dataset not found at {path}. Upload the CSV or change DATA_PATH.")
    df = pd.read_csv(path)
    print("Loaded dataset with shape:", df.shape)
    print("Columns:", df.columns.tolist())
    return df


def detect_text_and_label_columns(df: pd.DataFrame):
    # Prefer conventional column names
    text_cols = [c for c in df.columns if c.lower() in ("text", "tweet", "post", "content", "comment")]
    if len(text_cols) == 0:
        # fallback: choose the first string-like column
        for c in df.columns:
            if df[c].dtype == object:
                text_cols = [c]
                break
    label_candidates = [c for c in df.columns if c.lower() in ("label", "labels", "target", "abusive", "emotion", "class")]

    # fallback: any numeric or categorical column not the text column
    if len(label_candidates) == 0:
        label_candidates = [c for c in df.columns if c not in text_cols]

    text_col = text_cols[0]
    # If multiple label candidates, keep them all (multi-label / multi-task possibility)
    label_cols = label_candidates

    return text_col, label_cols


# -------------- 5) Load, inspect and preprocess labels --------------

df = load_and_inspect(DATA_PATH)
text_col, label_cols = detect_text_and_label_columns(df)
print(f"Auto-detected text column: {text_col}")
print(f"Auto-detected label columns: {label_cols}")

# Process labels into a single label array or multi-label matrix
multi_label = False

# If there is exactly one label column, check its unique values
if len(label_cols) == 1:
    lab = df[label_cols[0]]
    # If cells contain lists/strings with commas -> multi-label
    if lab.dtype == object and lab.str.contains(",").any():
        # treat as multi-label strings separated by commas
        mlb = MultiLabelBinarizer()
        labels = mlb.fit_transform(lab.fillna("").apply(lambda x: [i.strip() for i in str(x).split(",") if i.strip()]))
        label_names = mlb.classes_.tolist()
        multi_label = True
    else:
        # single column categorical or numeric label
        # Map string labels to ints, keep ints as-is
        if lab.dtype == object:
            label_map = {v: i for i, v in enumerate(sorted(lab.dropna().unique()))}
            labels = lab.map(label_map).astype(int).values
            label_names = [str(x) for x in sorted(lab.dropna().unique())]
        else:
            labels = lab.fillna(0).astype(int).values
            label_names = sorted(df[label_cols[0]].dropna().unique())
else:
    # Multiple columns -> assume multi-label binary columns (0/1) or categorical indicators
    # Convert to matrix
    lab_df = df[label_cols].fillna(0)
    # If all columns are numeric 0/1 -> multi-label
    if ((lab_df.dtypes == int) | (lab_df.dtypes == float)).all():
        labels = lab_df.astype(int).values
        label_names = label_cols
        multi_label = True
    else:
        # Otherwise attempt to encode each column's categories (one-hot concat)
        encoded_cols = []
        label_names = []
        for c in label_cols:
            if lab_df[c].dtype == object:
                vals = sorted(lab_df[c].dropna().unique())
                m = {v: i for i, v in enumerate(vals)}
                encoded = lab_df[c].map(lambda x: m[x] if pd.notna(x) else 0).astype(int).values
                encoded_cols.append(encoded.reshape(-1, 1))
                label_names.append(c)
            else:
                encoded_cols.append(lab_df[c].astype(int).values.reshape(-1, 1))
                label_names.append(c)
        labels = np.concatenate(encoded_cols, axis=1)
        multi_label = True

print("Multi-label task:", multi_label)
print("Label names:", label_names)

# Add a clean text column
texts = df[text_col].astype(str).fillna("").values

# Build a DataFrame for HuggingFace
proc_df = pd.DataFrame({"text": texts})
# Attach label columns in a format that HuggingFace wants
if multi_label:
    # labels is an array of shape (n_samples, n_labels)
    for i, name in enumerate(label_names):
        proc_df[f"label_{i}"] = labels[:, i]
    # For the trainer, we will keep 'labels' as a list of lists (or matrix)
    proc_df["labels"] = labels.tolist()
else:
    proc_df["labels"] = labels.tolist()

print("Prepared DataFrame shape:", proc_df.shape)

# -------------- 6) Make HuggingFace Dataset and split --------------

hf_dataset = Dataset.from_pandas(proc_df)
train_val = hf_dataset.train_test_split(test_size=0.1, seed=SEED, stratify_by_column="labels" if not multi_label else None)
# If multi-label, stratify is not supported easily; we skip stratify for multi-label
if multi_label:
    train_val = hf_dataset.train_test_split(test_size=0.1, seed=SEED)

raw_datasets = DatasetDict({
    "train": train_val["train"],
    "validation": train_val["test"]
})

print(raw_datasets)

# -------------- 7) Tokenization --------------

tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)

def tokenize_function(batch: Dict[str, Any]):
    return tokenizer(batch["text"], truncation=True, padding=True)

tokenized = raw_datasets.map(tokenize_function, batched=True)

# Prepare labels in the expected format for Trainer
if multi_label:
    # convert list labels to float arrays
    def format_multilabel(example):
        example["labels"] = [float(x) for x in example["labels"]]
        return example
    tokenized = tokenized.map(format_multilabel, batched=False)
else:
    tokenized = tokenized.map(lambda x: {"labels": x["labels"]}, batched=True)

# Remove unnecessary columns and set format
columns_to_remove = [c for c in tokenized["train"].column_names if c not in ("input_ids", "attention_mask", "labels")]
if columns_to_remove:
    tokenized = tokenized.remove_columns(columns_to_remove)

# set PyTorch format
tokenized.set_format(type="torch")

# Data collator
data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

# -------------- 8) Model setup + LoRA (PEFT) --------------

# Determine number of labels
if multi_label:
    num_labels = labels.shape[1]
else:
    num_labels = int(np.max(labels)) + 1 if np.max(labels) >= 1 else 2

print("num_labels:", num_labels)

base_model = AutoModelForSequenceClassification.from_pretrained(MODEL_CHECKPOINT, num_labels=num_labels)

# Configure LoRA
lora_config = LoraConfig(
    r=8,
    lora_alpha=32,
    target_modules=["query", "key", "value"],
    lora_dropout=0.1,
    bias="none",
    task_type="SEQ_CLS",
)

model = get_peft_model(base_model, lora_config)

print("Number of trainable parameters (LoRA adapters):")
trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
all_params = sum(p.numel() for p in model.parameters())
print(f"trainable: {trainable_params:,} | all: {all_params:,} | trainable%: {100*trainable_params/all_params:.4f}")

# -------------- 9) Metrics --------------

import evaluate

accuracy_metric = evaluate.load("accuracy")
precision_metric = evaluate.load("precision")
recall_metric = evaluate.load("recall")


def compute_metrics(eval_pred):
    logits, labels_batch = eval_pred
    if multi_label:
        # sigmoid + threshold 0.5 for multi-label
        probs = torch.sigmoid(torch.from_numpy(logits))
        preds = (probs >= 0.5).long().numpy()
        labels_np = np.array(labels_batch, dtype=int)
        # compute micro F1 using sklearn via evaluate
        from sklearn.metrics import f1_score
        f1 = f1_score(labels_np, preds, average='micro')
        acc = (labels_np == preds).mean()
        return {"f1_micro": f1, "accuracy": float(acc)}
    else:
        preds = np.argmax(logits, axis=-1)
        acc = accuracy_metric.compute(predictions=preds, references=labels_batch)["accuracy"]
        # compute precision/recall/f1 (macro)
        from sklearn.metrics import precision_score, recall_score, f1_score
        precision = precision_score(labels_batch, preds, average="macro", zero_division=0)
        recall = recall_score(labels_batch, preds, average="macro", zero_division=0)
        f1 = f1_score(labels_batch, preds, average="macro", zero_division=0)
        return {"accuracy": acc, "precision_macro": precision, "recall_macro": recall, "f1_macro": f1}

# -------------- 10) TrainingArguments and Trainer --------------

training_args = TrainingArguments(
    output_dir=OUTPUT_DIR,
    evaluation_strategy="epoch",
    save_strategy="epoch",
    per_device_train_batch_size=BATCH_SIZE,
    per_device_eval_batch_size=BATCH_SIZE,
    num_train_epochs=NUM_EPOCHS,
    learning_rate=LEARNING_RATE,
    weight_decay=0.01,
    logging_dir="./logs",
    logging_strategy="steps",
    logging_steps=50,
    seed=SEED,
    load_best_model_at_end=True,
    metric_for_best_model="f1_micro" if multi_label else "f1_macro",
    greater_is_better=True,
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized['train'],
    eval_dataset=tokenized['validation'],
    tokenizer=tokenizer,
    data_collator=data_collator,
    compute_metrics=compute_metrics,
)

# -------------- 11) Train --------------

print("Starting training...")
trainer.train()

# -------------- 12) Save the LoRA adapter & full model (adapter + base config) --------------
os.makedirs(OUTPUT_DIR, exist_ok=True)
model.save_pretrained(os.path.join(OUTPUT_DIR, "lora_adapter"))
# Save the base tokenizer & model config as well
tokenizer.save_pretrained(os.path.join(OUTPUT_DIR, "tokenizer"))

print("Saved adapter to:", os.path.join(OUTPUT_DIR, "lora_adapter"))

# -------------- 13) Example inference using the saved LoRA adapter --------------

# Reload base + adapter for inference
base_for_infer = AutoModelForSequenceClassification.from_pretrained(MODEL_CHECKPOINT, num_labels=num_labels)
peft_model = PeftModel.from_pretrained(base_for_infer, os.path.join(OUTPUT_DIR, "lora_adapter"))
peft_model.eval()
peft_model.to("cuda" if torch.cuda.is_available() else "cpu")

sample_texts = ["I love this product!", "You are a complete idiot."]
inputs = tokenizer(sample_texts, truncation=True, padding=True, return_tensors="pt")
inputs = {k: v.to(peft_model.device) for k, v in inputs.items()}
with torch.no_grad():
    outputs = peft_model(**inputs)
    logits = outputs.logits
    if multi_label:
        probs = torch.sigmoid(logits).cpu().numpy()
        print("Multi-label probabilities:", probs)
    else:
        probs = torch.nn.functional.softmax(logits, dim=-1).cpu().numpy()
        preds = probs.argmax(axis=-1)
        print("Predictions:", preds)
        print("Probabilities:", probs)

print("Done.")

# Google Colab Executable Code: Train LoRA Models for Abusive Detection and Pre-Post Suggestion
# - Detection: Fine-tune DistilBERT classifier with LoRA on hate_speech_offensive dataset.
# - Suggestion: Fine-tune BART with LoRA on ParaDetox for rephrasing toxic to non-toxic.
# Run this in a Colab notebook (GPU recommended).



!pip install -q transformers peft datasets accelerate bitsandbytes evaluate

import torch
from datasets import load_dataset
from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForSeq2SeqLM, TrainingArguments, Trainer
from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training
from sklearn.metrics import accuracy_score
import numpy as np

import pandas as pd
from datasets import Dataset, DatasetDict
from sklearn.model_selection import train_test_split
try:
    df = pd.read_csv("labeled_data.csv")
    df = df[['tweet', 'class']].rename(columns={'tweet': 'text', 'class': 'label'})
    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)
    detection_dataset = DatasetDict({
        "train": Dataset.from_pandas(train_df),
        "test": Dataset.from_pandas(test_df)
    })
except Exception as e:
    print(f"Error loading CSV dataset: {e}")
    raise

# Tokenizer and Model
det_model_name = "distilbert-base-uncased"
det_tokenizer = AutoTokenizer.from_pretrained(det_model_name)

def det_preprocess(examples):
    return det_tokenizer(examples['tweet'], truncation=True, padding=True, max_length=128)

det_tokenized = detection_dataset.map(det_preprocess, batched=True)

# LoRA Config
lora_config = LoraConfig(r=16, lora_alpha=32, target_modules=["attention.q_lin", "attention.v_lin"], lora_dropout=0.05, bias="none", task_type="SEQ_CLS")

# Load model with 8-bit quant
from transformers import BitsAndBytesConfig
quant_config = BitsAndBytesConfig(load_in_8bit=True)
det_model = AutoModelForSequenceClassification.from_pretrained(det_model_name, num_labels=3, quantization_config=quant_config)  # 0:hate, 1:offensive, 2:neither

det_model = prepare_model_for_kbit_training(det_model)
det_model = get_peft_model(det_model, lora_config)

# Metrics
def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)
    return {"accuracy": accuracy_score(labels, predictions)}

# Training Args
det_training_args = TrainingArguments(
    output_dir="./det_results",
    evaluation_strategy="epoch",
    learning_rate=2e-5,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=3,
    weight_decay=0.01,
    fp16=True
)

# Trainer
det_trainer = Trainer(
    model=det_model,
    args=det_training_args,
    train_dataset=det_tokenized["train"],
    eval_dataset=det_tokenized["test"],
    tokenizer=det_tokenizer,
    compute_metrics=compute_metrics
)

# Train Detection Model
print("Training Abusive Detection Model...")
det_trainer.train()
det_trainer.save_model("./lora_abusive_detector")

# --- Part 2: Pre-Post Suggestion (Detoxification/Rephrasing) ---
# Load ParaDetox dataset
sugg_dataset = load_dataset("s-nlp/paradetox")
sugg_dataset = sugg_dataset['train'].train_test_split(test_size=0.2)

# Tokenizer and Model (BART for seq2seq)
sugg_model_name = "facebook/bart-base"
sugg_tokenizer = AutoTokenizer.from_pretrained(sugg_model_name)

def sugg_preprocess(examples):
    inputs = [f"detoxify: {text}" for text in examples['toxic_sentence']]  # Prefix for conditioning
    model_inputs = sugg_tokenizer(inputs, max_length=128, truncation=True, padding=True)
    labels = sugg_tokenizer(examples['neutral_sentence'], max_length=128, truncation=True, padding=True)["input_ids"]
    model_inputs["labels"] = labels
    return model_inputs

sugg_tokenized = sugg_dataset.map(sugg_preprocess, batched=True)

# LoRA Config for Seq2Seq
sugg_lora_config = LoraConfig(r=16, lora_alpha=32, target_modules=["q_proj", "v_proj"], lora_dropout=0.05, bias="none", task_type="SEQ_2_SEQ_LM")

# Load model with quant
sugg_model = AutoModelForSeq2SeqLM.from_pretrained(sugg_model_name, quantization_config=quant_config)

sugg_model = prepare_model_for_kbit_training(sugg_model)
sugg_model = get_peft_model(sugg_model, sugg_lora_config)

# Training Args
sugg_training_args = TrainingArguments(
    output_dir="./sugg_results",
    evaluation_strategy="epoch",
    learning_rate=2e-5,
    per_device_train_batch_size=8,  # Smaller batch for seq2seq
    per_device_eval_batch_size=8,
    num_train_epochs=3,
    weight_decay=0.01,
    fp16=True
)

# Trainer (use default metrics for seq2seq, or add custom if needed)
sugg_trainer = Trainer(
    model=sugg_model,
    args=sugg_training_args,
    train_dataset=sugg_tokenized["train"],
    eval_dataset=sugg_tokenized["test"],
    tokenizer=sugg_tokenizer
)

# Train Suggestion Model
print("Training Pre-Post Suggestion Model...")
sugg_trainer.train()
sugg_trainer.save_model("./lora_suggestion_model")

# --- Inference Function: Detect and Suggest ---
def pre_post_suggest(text):
    # Detection
    device = "cuda" if torch.cuda.is_available() else "cpu"
    det_inputs = det_tokenizer(text, return_tensors="pt", truncation=True).to(device)
    det_model.to(device)
    det_outputs = det_model(**det_inputs)
    det_probs = torch.softmax(det_outputs.logits, dim=1)
    det_label_id = torch.argmax(det_probs).item()
    labels = ["hate speech", "offensive language", "neither"]
    det_conf = det_probs[0][det_label_id].item()
    det_label = labels[det_label_id]

    if det_label == "neither":
        return f"Post seems fine ({det_label}, conf: {det_conf:.2f}). Post as is: '{text}'"

    # Suggestion if abusive
    sugg_inputs = sugg_tokenizer(f"detoxify: {text}", return_tensors="pt", truncation=True).to(device)
    sugg_model.to(device)
    sugg_outputs = sugg_model.generate(**sugg_inputs, max_length=128)
    suggested = sugg_tokenizer.decode(sugg_outputs[0], skip_special_tokens=True)
    return f"Detected as {det_label} (conf: {det_conf:.2f}). Suggested: '{suggested}'"

# Example
example = "You are a total idiot and a bitch."
print(pre_post_suggest(example))

# Commented out IPython magic to ensure Python compatibility.
# %env WANDB_MODE=offline

# Corrected Google Colab Executable Code: Train LoRA Models for Abusive Detection and Pre-Post Suggestion
# - Detection: Fine-tune DistilBERT classifier with LoRA on hate_speech_offensive dataset.
# - Suggestion: Fine-tune BART with LoRA on ParaDetox for rephrasing toxic to non-toxic.
# Fixes: Use load_in_4bit=True for stable quantization (8bit has compatibility issues). Update pip installs for latest versions.
# Run this in a Colab notebook with GPU (Runtime > Change runtime type > T4 GPU).

!pip install -q --upgrade transformers peft datasets accelerate bitsandbytes evaluate

import torch
from datasets import load_dataset
from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForSeq2SeqLM, TrainingArguments, Trainer
from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training
from sklearn.metrics import accuracy_score
import numpy as np


import pandas as pd
from datasets import Dataset, DatasetDict
from sklearn.model_selection import train_test_split
df = pd.read_csv("labeled_data.csv")
df = df[['tweet', 'class']].rename(columns={'tweet': 'text', 'class': 'label'})
train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)
detection_dataset = DatasetDict({
    "train": Dataset.from_pandas(train_df),
    "test": Dataset.from_pandas(test_df)
})


# Tokenizer and Model
det_model_name = "distilbert-base-uncased"
det_tokenizer = AutoTokenizer.from_pretrained(det_model_name)

def det_preprocess(examples):
    return det_tokenizer(examples['tweet'], truncation=True, padding=True, max_length=128)

det_tokenized = detection_dataset.map(det_preprocess, batched=True)

# LoRA Config
lora_config = LoraConfig(r=16, lora_alpha=32, target_modules=["attention.q_lin", "attention.v_lin"], lora_dropout=0.05, bias="none", task_type="SEQ_CLS")

# Load model with 4-bit quant (fix for 8bit issues)
from transformers import BitsAndBytesConfig
quant_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.bfloat16
)
det_model = AutoModelForSequenceClassification.from_pretrained(det_model_name, num_labels=3, quantization_config=quant_config)  # 0:hate, 1:offensive, 2:neither

det_model = prepare_model_for_kbit_training(det_model)
det_model = get_peft_model(det_model, lora_config)

# Metrics
def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)
    return {"accuracy": accuracy_score(labels, predictions)}

# Training Args
det_training_args = TrainingArguments(
    output_dir="./det_results",
    evaluation_strategy="epoch",
    learning_rate=2e-5,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=3,
    weight_decay=0.01,
    fp16=True
)

# Trainer
det_trainer = Trainer(
    model=det_model,
    args=det_training_args,
    train_dataset=det_tokenized["train"],
    eval_dataset=det_tokenized["test"],
    tokenizer=det_tokenizer,
    compute_metrics=compute_metrics
)

# Train Detection Model
print("Training Abusive Detection Model...")
det_trainer.train()
det_trainer.save_model("./lora_abusive_detector")

# --- Part 2: Pre-Post Suggestion (Detoxification/Rephrasing) ---
# Load ParaDetox dataset
sugg_dataset = load_dataset("s-nlp/paradetox")
sugg_dataset = sugg_dataset['train'].train_test_split(test_size=0.2)

# Tokenizer and Model (BART for seq2seq)
sugg_model_name = "facebook/bart-base"
sugg_tokenizer = AutoTokenizer.from_pretrained(sugg_model_name)

def sugg_preprocess(examples):
    inputs = [f"detoxify: {text}" for text in examples['toxic_sentence']]  # Prefix for conditioning
    model_inputs = sugg_tokenizer(inputs, max_length=128, truncation=True, padding=True)
    labels = sugg_tokenizer(examples['neutral_sentence'], max_length=128, truncation=True, padding=True)["input_ids"]
    model_inputs["labels"] = labels
    return model_inputs

sugg_tokenized = sugg_dataset.map(sugg_preprocess, batched=True)

# LoRA Config for Seq2Seq
sugg_lora_config = LoraConfig(r=16, lora_alpha=32, target_modules=["q_proj", "v_proj"], lora_dropout=0.05, bias="none", task_type="SEQ_2_SEQ_LM")

# Load model with 4-bit quant
sugg_model = AutoModelForSeq2SeqLM.from_pretrained(sugg_model_name, quantization_config=quant_config)

sugg_model = prepare_model_for_kbit_training(sugg_model)
sugg_model = get_peft_model(sugg_model, sugg_lora_config)

# Training Args
sugg_training_args = TrainingArguments(
    output_dir="./sugg_results",
    evaluation_strategy="epoch",
    learning_rate=2e-5,
    per_device_train_batch_size=8,  # Smaller batch for seq2seq
    per_device_eval_batch_size=8,
    num_train_epochs=3,
    weight_decay=0.01,
    fp16=True
)

# Trainer (use default metrics for seq2seq, or add custom if needed)
sugg_trainer = Trainer(
    model=sugg_model,
    args=sugg_training_args,
    train_dataset=sugg_tokenized["train"],
    eval_dataset=sugg_tokenized["test"],
    tokenizer=sugg_tokenizer
)

# Train Suggestion Model
print("Training Pre-Post Suggestion Model...")
sugg_trainer.train()
sugg_trainer.save_model("./lora_suggestion_model")

# --- Inference Function: Detect and Suggest ---
def pre_post_suggest(text):
    # Detection
    device = "cuda" if torch.cuda.is_available() else "cpu"
    det_inputs = det_tokenizer(text, return_tensors="pt", truncation=True).to(device)
    det_model.to(device)
    det_outputs = det_model(**det_inputs)
    det_probs = torch.softmax(det_outputs.logits, dim=1)
    det_label_id = torch.argmax(det_probs).item()
    labels = ["hate speech", "offensive language", "neither"]
    det_conf = det_probs[0][det_label_id].item()
    det_label = labels[det_label_id]

    if det_label == "neither":
        return f"Post seems fine ({det_label}, conf: {det_conf:.2f}). Post as is: '{text}'"

    # Suggestion if abusive
    sugg_inputs = sugg_tokenizer(f"detoxify: {text}", return_tensors="pt", truncation=True).to(device)
    sugg_model.to(device)
    sugg_outputs = sugg_model.generate(**sugg_inputs, max_length=128)
    suggested = sugg_tokenizer.decode(sugg_outputs[0], skip_special_tokens=True)
    return f"Detected as {det_label} (conf: {det_conf:.2f}). Suggested: '{suggested}'"

# Example
example = "You are a total idiot and a bitch."
print(pre_post_suggest(example))

# Google Colab Executable Code: Train LoRA Models for Abusive Detection and Pre-Post Suggestion
# - Detection: Fine-tune DistilBERT classifier with LoRA on hate_speech_offensive dataset.
# - Suggestion: Fine-tune BART with LoRA on ParaDetox for rephrasing toxic to non-toxic.
# Fixes: Use eval_strategy, ensure compatible dependencies, stable 4-bit quantization.
# Run in Colab with GPU (Runtime > Change runtime type > T4 GPU).

!pip install -q --upgrade transformers==4.45.0 peft==0.13.0 datasets==3.0.1 accelerate==1.0.0 bitsandbytes==0.44.0 evaluate==0.4.3

import torch
from datasets import load_dataset
from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForSeq2SeqLM, TrainingArguments, Trainer
from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training
from sklearn.metrics import accuracy_score
import numpy as np

# --- Part 1: Abusive Detection (Classification) ---
# Load dataset
detection_dataset = load_dataset("hate_speech_offensive")
detection_dataset = detection_dataset['train'].train_test_split(test_size=0.2)

# Tokenizer and Model
det_model_name = "distilbert-base-uncased"
det_tokenizer = AutoTokenizer.from_pretrained(det_model_name)

def det_preprocess(examples):
    return det_tokenizer(examples['tweet'], truncation=True, padding=True, max_length=128)

det_tokenized = detection_dataset.map(det_preprocess, batched=True)

# LoRA Config
lora_config = LoraConfig(
    r=16,
    lora_alpha=32,
    target_modules=["attention.q_lin", "attention.v_lin"],
    lora_dropout=0.05,
    bias="none",
    task_type="SEQ_CLS"
)

# Load model with 4-bit quantization
from transformers import BitsAndBytesConfig
quant_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.bfloat16
)
det_model = AutoModelForSequenceClassification.from_pretrained(
    det_model_name,
    num_labels=3,  # 0:hate, 1:offensive, 2:neither
    quantization_config=quant_config
)

det_model = prepare_model_for_kbit_training(det_model)
det_model = get_peft_model(det_model, lora_config)

# Metrics
def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)
    return {"accuracy": accuracy_score(labels, predictions)}

# Training Args
det_training_args = TrainingArguments(
    output_dir="./det_results",
    eval_strategy="epoch",  # Corrected parameter
    learning_rate=2e-5,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=3,
    weight_decay=0.01,
    fp16=True,
    logging_steps=10,
    save_strategy="epoch",
    load_best_model_at_end=True,
    metric_for_best_model="accuracy",
    report_to="none"
)

# Trainer
det_trainer = Trainer(
    model=det_model,
    args=det_training_args,
    train_dataset=det_tokenized["train"],
    eval_dataset=det_tokenized["test"],
    tokenizer=det_tokenizer,
    compute_metrics=compute_metrics
)

# Train Detection Model
print("Training Abusive Detection Model...")
det_trainer.train()
det_trainer.save_model("./lora_abusive_detector")

# --- Part 2: Pre-Post Suggestion (Detoxification/Rephrasing) ---
# Load ParaDetox dataset
sugg_dataset = load_dataset("s-nlp/paradetox")
sugg_dataset = sugg_dataset['train'].train_test_split(test_size=0.2)

# Tokenizer and Model (BART for seq2seq)
sugg_model_name = "facebook/bart-base"
sugg_tokenizer = AutoTokenizer.from_pretrained(sugg_model_name)

def sugg_preprocess(examples):
    inputs = [f"detoxify: {text}" for text in examples['toxic_sentence']]
    model_inputs = sugg_tokenizer(inputs, max_length=128, truncation=True, padding=True)
    labels = sugg_tokenizer(examples['neutral_sentence'], max_length=128, truncation=True, padding=True)["input_ids"]
    model_inputs["labels"] = labels
    return model_inputs

sugg_tokenized = sugg_dataset.map(sugg_preprocess, batched=True)

# LoRA Config for Seq2Seq
sugg_lora_config = LoraConfig(
    r=16,
    lora_alpha=32,
    target_modules=["q_proj", "v_proj"],
    lora_dropout=0.05,
    bias="none",
    task_type="SEQ_2_SEQ_LM"
)

# Load model with 4-bit quantization
sugg_model = AutoModelForSeq2SeqLM.from_pretrained(sugg_model_name, quantization_config=quant_config)

sugg_model = prepare_model_for_kbit_training(sugg_model)
sugg_model = get_peft_model(sugg_model, sugg_lora_config)

# Training Args
sugg_training_args = TrainingArguments(
    output_dir="./sugg_results",
    eval_strategy="epoch",  # Corrected parameter
    learning_rate=2e-5,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=3,
    weight_decay=0.01,
    fp16=True,
    logging_steps=10,
    save_strategy="epoch",
    load_best_model_at_end=True,
    report_to="none"
)

# Trainer
sugg_trainer = Trainer(
    model=sugg_model,
    args=sugg_training_args,
    train_dataset=sugg_tokenized["train"],
    eval_dataset=sugg_tokenized["test"],
    tokenizer=sugg_tokenizer
)

# Train Suggestion Model
print("Training Pre-Post Suggestion Model...")
sugg_trainer.train()
sugg_trainer.save_model("./lora_suggestion_model")

# --- Inference Function: Detect and Suggest ---
def pre_post_suggest(text):
    # Detection
    device = "cuda" if torch.cuda.is_available() else "cpu"
    det_inputs = det_tokenizer(text, return_tensors="pt", truncation=True).to(device)
    det_model.to(device)
    with torch.no_grad():
        det_outputs = det_model(**det_inputs)
    det_probs = torch.softmax(det_outputs.logits, dim=1)
    det_label_id = torch.argmax(det_probs).item()
    labels = ["hate speech", "offensive language", "neither"]
    det_conf = det_probs[0][det_label_id].item()
    det_label = labels[det_label_id]

    if det_label == "neither":
        return f"Post seems fine ({det_label}, conf: {det_conf:.2f}). Post as is: '{text}'"

    # Suggestion if abusive
    sugg_inputs = sugg_tokenizer(f"detoxify: {text}", return_tensors="pt", truncation=True).to(device)
    sugg_model.to(device)
    with torch.no_grad():
        sugg_outputs = sugg_model.generate(**sugg_inputs, max_length=128, num_beams=4)
    suggested = sugg_tokenizer.decode(sugg_outputs[0], skip_special_tokens=True)
    return f"Detected as {det_label} (conf: {det_conf:.2f}). Suggested: '{suggested}'"

# Example
example = "You are a total idiot and a bitch."
print(pre_post_suggest(example))

!pip list | grep -E "transformers|peft|bitsandbytes|accelerate|datasets|evaluate|torch"

# Google Colab Executable Code: Train LoRA Models for Abusive Detection and Pre-Text Suggestion
# - Detection: Fine-tune DistilBERT classifier with LoRA on hate_speech_offensive dataset.
# - Suggestion: Fine-tune BART with LoRA on ParaDetox for rephrasing toxic to non-toxic.
# Fixes: Stable 4-bit quantization (float16, no double quant), pinned library versions, gradient checkpointing.
# Run in Colab with GPU (Runtime > Change runtime type > T4 GPU).

!pip install -q transformers==4.45.0 peft==0.13.0 datasets==3.0.1 accelerate==1.0.0 bitsandbytes==0.44.0 evaluate==0.4.3 torch==2.4.1

import torch
from datasets import load_dataset
from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForSeq2SeqLM, TrainingArguments, Trainer
from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training
from sklearn.metrics import accuracy_score
import numpy as np

import pandas as pd
from datasets import Dataset, DatasetDict
from sklearn.model_selection import train_test_split
df = pd.read_csv("labeled_data.csv")
df = df[['tweet', 'class']].rename(columns={'tweet': 'text', 'class': 'label'})
train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)
detection_dataset = DatasetDict({
    "train": Dataset.from_pandas(train_df),
    "test": Dataset.from_pandas(test_df)
})

import pandas as pd
from datasets import Dataset, DatasetDict
from sklearn.model_selection import train_test_split
try:
    df = pd.read_csv("labeled_data.csv")
    df = df[['tweet', 'class']].rename(columns={'tweet': 'text', 'class': 'label'})
    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)
    detection_dataset = DatasetDict({
        "train": Dataset.from_pandas(train_df),
        "test": Dataset.from_pandas(test_df)
    })
except Exception as e:
    print(f"Error loading CSV dataset: {e}")
    raise


# Tokenizer and Model
det_model_name = "distilbert-base-uncased"
det_tokenizer = AutoTokenizer.from_pretrained(det_model_name)

def det_preprocess(examples):
    return det_tokenizer(examples['tweet'], truncation=True, padding=True, max_length=128)

det_tokenized = detection_dataset.map(det_preprocess, batched=True)

# LoRA Config
lora_config = LoraConfig(
    r=8,  # Reduced rank for stability
    lora_alpha=16,
    target_modules=["attention.q_lin", "attention.v_lin"],
    lora_dropout=0.1,
    bias="none",
    task_type="SEQ_CLS"
)

# Load model with 4-bit quantization
from transformers import BitsAndBytesConfig
quant_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_use_double_quant=False,  # Disable double quant to avoid weight issues
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.float16  # Use float16 for stability
)
try:
    det_model = AutoModelForSequenceClassification.from_pretrained(
        det_model_name,
        num_labels=3,  # 0:hate, 1:offensive, 2:neither
        quantization_config=quant_config,
        device_map={"": 0},  # Explicitly place on GPU 0
        torch_dtype=torch.float16  # Ensure consistent dtype
    )
except Exception as e:
    print(f"Error loading model: {e}")
    raise
det_model = prepare_model_for_kbit_training(det_model, use_gradient_checkpointing=True)  # Enable gradient checkpointing
det_model = get_peft_model(det_model, lora_config)

# Metrics
def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)
    return {"accuracy": accuracy_score(labels, predictions)}

# Training Args
det_training_args = TrainingArguments(
    output_dir="./det_results",
    eval_strategy="epoch",
    learning_rate=2e-5,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=3,
    weight_decay=0.01,
    fp16=True,
    logging_steps=10,
    save_strategy="epoch",
    load_best_model_at_end=True,
    metric_for_best_model="accuracy",
    report_to="none",
    gradient_accumulation_steps=4
)

# Trainer
det_trainer = Trainer(
    model=det_model,
    args=det_training_args,
    train_dataset=det_tokenized["train"],
    eval_dataset=det_tokenized["test"],
    tokenizer=det_tokenizer,
    compute_metrics=compute_metrics
)

# Train Detection Model
print("Training Abusive Detection Model...")
try:
    det_trainer.train()
    det_trainer.save_model("./lora_abusive_detector")
except Exception as e:
    print(f"Error during training: {e}")
    raise

# --- Part 2: Pre-Text Suggestion (Detoxification/Rephrasing) ---
# Load ParaDetox dataset
try:
    sugg_dataset = load_dataset("s-nlp/paradetox")
    sugg_dataset = sugg_dataset['train'].train_test_split(test_size=0.2)
except Exception as e:
    print(f"Error loading dataset: {e}")
    raise

# Tokenizer and Model (BART for seq2seq)
sugg_model_name = "facebook/bart-base"
sugg_tokenizer = AutoTokenizer.from_pretrained(sugg_model_name)

def sugg_preprocess(examples):
    inputs = [f"detoxify: {text}" for text in examples['toxic_sentence']]
    model_inputs = sugg_tokenizer(inputs, max_length=128, truncation=True, padding=True)
    labels = sugg_tokenizer(examples['neutral_sentence'], max_length=128, truncation=True, padding=True)["input_ids"]
    model_inputs["labels"] = labels
    return model_inputs

sugg_tokenized = sugg_dataset.map(sugg_preprocess, batched=True)

# LoRA Config for Seq2Seq
sugg_lora_config = LoraConfig(
    r=8,
    lora_alpha=16,
    target_modules=["q_proj", "v_proj"],
    lora_dropout=0.1,
    bias="none",
    task_type="SEQ_2_SEQ_LM"
)

# Load model with 4-bit quantization
try:
    sugg_model = AutoModelForSeq2SeqLM.from_pretrained(
        sugg_model_name,
        quantization_config=quant_config,
        device_map={"": 0},
        torch_dtype=torch.float16
    )
except Exception as e:
    print(f"Error loading model: {e}")
    raise
sugg_model = prepare_model_for_kbit_training(sugg_model, use_gradient_checkpointing=True)
sugg_model = get_peft_model(sugg_model, sugg_lora_config)

# Training Args
sugg_training_args = TrainingArguments(
    output_dir="./sugg_results",
    eval_strategy="epoch",
    learning_rate=2e-5,
    per_device_train_batch_size=4,
    per_device_eval_batch_size=4,
    num_train_epochs=3,
    weight_decay=0.01,
    fp16=True,
    logging_steps=10,
    save_strategy="epoch",
    load_best_model_at_end=True,
    report_to="none",
    gradient_accumulation_steps=4
)

# Trainer
sugg_trainer = Trainer(
    model=sugg_model,
    args=sugg_training_args,
    train_dataset=sugg_tokenized["train"],
    eval_dataset=sugg_tokenized["test"],
    tokenizer=sugg_tokenizer
)

# Train Suggestion Model
print("Training Pre-Text Suggestion Model...")
try:
    sugg_trainer.train()
    sugg_trainer.save_model("./lora_suggestion_model")
except Exception as e:
    print(f"Error during training: {e}")
    raise

# --- Inference Function: Detect and Suggest ---
def pre_post_suggest(text):
    device = "cuda" if torch.cuda.is_available() else "cpu"
    # Detection
    det_inputs = det_tokenizer(text, return_tensors="pt", truncation=True).to(device)
    det_model.to(device)
    with torch.no_grad():
        det_outputs = det_model(**det_inputs)
    det_probs = torch.softmax(det_outputs.logits, dim=1)
    det_label_id = torch.argmax(det_probs).item()
    labels = ["hate speech", "offensive language", "neither"]
    det_conf = det_probs[0][det_label_id].item()
    det_label = labels[det_label_id]

    if det_label == "neither":
        return f"Post seems fine ({det_label}, conf: {det_conf:.2f}). Post as is: '{text}'"

    # Suggestion if abusive
    sugg_inputs = sugg_tokenizer(f"detoxify: {text}", return_tensors="pt", truncation=True).to(device)
    sugg_model.to(device)
    with torch.no_grad():
        sugg_outputs = sugg_model.generate(**sugg_inputs, max_length=128, num_beams=4)
    suggested = sugg_tokenizer.decode(sugg_outputs[0], skip_special_tokens=True)
    return f"Detected as {det_label} (conf: {det_conf:.2f}). Suggested: '{suggested}'"

# Examples
print(pre_post_suggest("This is a nice day!"))
print(pre_post_suggest("You are a total idiot and a bitch."))
print(pre_post_suggest("I hate this retard show."))

# Google Colab Executable Code: Train LoRA Models for Abusive Detection and Pre-Text Suggestion
# - Detection: Fine-tune DistilBERT classifier with LoRA on hate_speech_offensive dataset.
# - Suggestion: Fine-tune BART with LoRA on ParaDetox for rephrasing toxic to non-toxic.
# Fixes: Use 8-bit quantization instead of 4-bit to avoid bitsandbytes AssertionError, pinned versions, gradient checkpointing.
# Run in Colab with GPU (Runtime > Change runtime type > T4 GPU).

!pip install -q transformers==4.45.0 peft==0.13.0 datasets==3.0.1 accelerate==1.0.0 bitsandbytes==0.44.0 evaluate==0.4.3 torch==2.4.1

import torch
from datasets import load_dataset
from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForSeq2SeqLM, TrainingArguments, Trainer
from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training
from sklearn.metrics import accuracy_score
import numpy as np
import pandas as pd
from datasets import Dataset, DatasetDict
from sklearn.model_selection import train_test_split
try:
    df = pd.read_csv("labeled_data.csv")
    df = df[['tweet', 'class']].rename(columns={'tweet': 'text', 'class': 'label'})
    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)
    detection_dataset = DatasetDict({
        "train": Dataset.from_pandas(train_df),
        "test": Dataset.from_pandas(test_df)
    })
except Exception as e:
    print(f"Error loading CSV dataset: {e}")
    raise
# Tokenizer and Model
det_model_name = "distilbert-base-uncased"
det_tokenizer = AutoTokenizer.from_pretrained(det_model_name)

def det_preprocess(examples):
    return det_tokenizer(examples['tweet'], truncation=True, padding=True, max_length=128)

det_tokenized = detection_dataset.map(det_preprocess, batched=True)

# LoRA Config
lora_config = LoraConfig(
    r=8,
    lora_alpha=16,
    target_modules=["attention.q_lin", "attention.v_lin"],
    lora_dropout=0.1,
    bias="none",
    task_type="SEQ_CLS"
)

# Load model with 8-bit quantization (stable alternative to 4-bit)
from transformers import BitsAndBytesConfig
quant_config = BitsAndBytesConfig(
    load_in_8bit=True,
    llm_int8_threshold=6.0  # Default threshold for outliers
)
try:
    det_model = AutoModelForSequenceClassification.from_pretrained(
        det_model_name,
        num_labels=3,  # 0:hate, 1:offensive, 2:neither
        quantization_config=quant_config,
        device_map="auto",  # Auto device placement
        torch_dtype=torch.float16  # Consistent dtype
    )
except Exception as e:
    print(f"Error loading model: {e}")
    raise
det_model = prepare_model_for_kbit_training(det_model, use_gradient_checkpointing=True)
det_model = get_peft_model(det_model, lora_config)

# Metrics
def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)
    return {"accuracy": accuracy_score(labels, predictions)}

# Training Args
det_training_args = TrainingArguments(
    output_dir="./det_results",
    eval_strategy="epoch",
    learning_rate=2e-5,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=3,
    weight_decay=0.01,
    fp16=True,
    logging_steps=10,
    save_strategy="epoch",
    load_best_model_at_end=True,
    metric_for_best_model="accuracy",
    report_to="none",
    gradient_accumulation_steps=4
)

# Trainer
det_trainer = Trainer(
    model=det_model,
    args=det_training_args,
    train_dataset=det_tokenized["train"],
    eval_dataset=det_tokenized["test"],
    tokenizer=det_tokenizer,
    compute_metrics=compute_metrics
)

# Train Detection Model
print("Training Abusive Detection Model...")
try:
    det_trainer.train()
    det_trainer.save_model("./lora_abusive_detector")
except Exception as e:
    print(f"Error during training: {e}")
    raise

# --- Part 2: Pre-Text Suggestion (Detoxification/Rephrasing) ---
# Load ParaDetox dataset
try:
    sugg_dataset = load_dataset("s-nlp/paradetox")
    sugg_dataset = sugg_dataset['train'].train_test_split(test_size=0.2)
except Exception as e:
    print(f"Error loading dataset: {e}")
    raise

# Tokenizer and Model (BART for seq2seq)
sugg_model_name = "facebook/bart-base"
sugg_tokenizer = AutoTokenizer.from_pretrained(sugg_model_name)

def sugg_preprocess(examples):
    inputs = [f"detoxify: {text}" for text in examples['toxic_sentence']]
    model_inputs = sugg_tokenizer(inputs, max_length=128, truncation=True, padding=True)
    labels = sugg_tokenizer(examples['neutral_sentence'], max_length=128, truncation=True, padding=True)["input_ids"]
    model_inputs["labels"] = labels
    return model_inputs

sugg_tokenized = sugg_dataset.map(sugg_preprocess, batched=True)

# LoRA Config for Seq2Seq
sugg_lora_config = LoraConfig(
    r=8,
    lora_alpha=16,
    target_modules=["q_proj", "v_proj"],
    lora_dropout=0.1,
    bias="none",
    task_type="SEQ_2_SEQ_LM"
)

# Load model with 8-bit quantization
try:
    sugg_model = AutoModelForSeq2SeqLM.from_pretrained(
        sugg_model_name,
        quantization_config=quant_config,
        device_map="auto",
        torch_dtype=torch.float16
    )
except Exception as e:
    print(f"Error loading model: {e}")
    raise
sugg_model = prepare_model_for_kbit_training(sugg_model, use_gradient_checkpointing=True)
sugg_model = get_peft_model(sugg_model, sugg_lora_config)

# Training Args
sugg_training_args = TrainingArguments(
    output_dir="./sugg_results",
    eval_strategy="epoch",
    learning_rate=2e-5,
    per_device_train_batch_size=4,
    per_device_eval_batch_size=4,
    num_train_epochs=3,
    weight_decay=0.01,
    fp16=True,
    logging_steps=10,
    save_strategy="epoch",
    load_best_model_at_end=True,
    report_to="none",
    gradient_accumulation_steps=4
)

# Trainer
sugg_trainer = Trainer(
    model=sugg_model,
    args=sugg_training_args,
    train_dataset=sugg_tokenized["train"],
    eval_dataset=sugg_tokenized["test"],
    tokenizer=sugg_tokenizer
)

# Train Suggestion Model
print("Training Pre-Text Suggestion Model...")
try:
    sugg_trainer.train()
    sugg_trainer.save_model("./lora_suggestion_model")
except Exception as e:
    print(f"Error during training: {e}")
    raise

# --- Inference Function: Detect and Suggest ---
def pre_post_suggest(text):
    device = "cuda" if torch.cuda.is_available() else "cpu"
    # Detection
    det_inputs = det_tokenizer(text, return_tensors="pt", truncation=True).to(device)
    det_model.to(device)
    with torch.no_grad():
        det_outputs = det_model(**det_inputs)
    det_probs = torch.softmax(det_outputs.logits, dim=1)
    det_label_id = torch.argmax(det_probs).item()
    labels = ["hate speech", "offensive language", "neither"]
    det_conf = det_probs[0][det_label_id].item()
    det_label = labels[det_label_id]

    if det_label == "neither":
        return f"Post seems fine ({det_label}, conf: {det_conf:.2f}). Post as is: '{text}'"

    # Suggestion if abusive
    sugg_inputs = sugg_tokenizer(f"detoxify: {text}", return_tensors="pt", truncation=True).to(device)
    sugg_model.to(device)
    with torch.no_grad():
        sugg_outputs = sugg_model.generate(**sugg_inputs, max_length=128, num_beams=4)
    suggested = sugg_tokenizer.decode(sugg_outputs[0], skip_special_tokens=True)
    return f"Detected as {det_label} (conf: {det_conf:.2f}). Suggested: '{suggested}'"

# Examples
print(pre_post_suggest("This is a nice day!"))
print(pre_post_suggest("You are a total idiot and a bitch."))
print(pre_post_suggest("I hate this retard show."))

# Google Colab Executable Code: Train LoRA Models for Abusive Detection and Pre-Post Suggestion
# - Detection: Fine-tune DistilBERT classifier with LoRA on hate_speech_offensive dataset.
# - Suggestion: Fine-tune BART with LoRA on ParaDetox for rephrasing toxic to non-toxic.
# Fixes: Use correct 'tweet' column for hate_speech_offensive, no quantization, pinned versions.
# Run in Colab with GPU (Runtime > Change runtime type > T4 GPU).

!pip install -q transformers==4.45.0 peft==0.13.0 datasets==3.0.1 accelerate==1.0.0 evaluate==0.4.3 torch==2.4.1

import torch
from datasets import load_dataset
from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForSeq2SeqLM, TrainingArguments, Trainer
from peft import LoraConfig, get_peft_model
from sklearn.metrics import accuracy_score
import numpy as np

# --- Part 1: Abusive Detection (Classification) ---
# Load dataset
try:
    detection_dataset = load_dataset("hate_speech_offensive")
    detection_dataset = detection_dataset['train'].train_test_split(test_size=0.2)
except Exception as e:
    print(f"Error loading dataset: {e}")
    raise

# Verify dataset columns
print("Detection dataset columns:", detection_dataset['train'].column_names)

# Tokenizer and Model
det_model_name = "distilbert-base-uncased"
det_tokenizer = AutoTokenizer.from_pretrained(det_model_name)

def det_preprocess(examples):
    return det_tokenizer(examples['tweet'], truncation=True, padding=True, max_length=128)  # Use 'tweet' column

det_tokenized = detection_dataset.map(det_preprocess, batched=True)

# LoRA Config
lora_config = LoraConfig(
    r=8,
    lora_alpha=16,
    target_modules=["attention.q_lin", "attention.v_lin"],
    lora_dropout=0.1,
    bias="none",
    task_type="SEQ_CLS"
)

# Load model without quantization
try:
    det_model = AutoModelForSequenceClassification.from_pretrained(
        det_model_name,
        num_labels=3,  # 0:hate, 1:offensive, 2:neither
        torch_dtype=torch.float16,
        device_map="auto"
    )
except Exception as e:
    print(f"Error loading detection model: {e}")
    raise
det_model = get_peft_model(det_model, lora_config)

# Metrics
def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)
    return {"accuracy": accuracy_score(labels, predictions)}

# Training Args
det_training_args = TrainingArguments(
    output_dir="./det_results",
    eval_strategy="epoch",
    learning_rate=2e-5,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=3,
    weight_decay=0.01,
    fp16=True,
    logging_steps=10,
    save_strategy="epoch",
    load_best_model_at_end=True,
    metric_for_best_model="accuracy",
    report_to="none",
    gradient_accumulation_steps=4,
    gradient_checkpointing=True
)

# Trainer
det_trainer = Trainer(
    model=det_model,
    args=det_training_args,
    train_dataset=det_tokenized["train"],
    eval_dataset=det_tokenized["test"],
    tokenizer=det_tokenizer,
    compute_metrics=compute_metrics
)

# Train Detection Model
print("Training Abusive Detection Model...")
try:
    det_trainer.train()
    det_trainer.save_model("./lora_abusive_detector")
except Exception as e:
    print(f"Error during detection training: {e}")
    raise

# --- Part 2: Pre-Text Suggestion (Detoxification/Rephrasing) ---
# Load ParaDetox dataset
try:
    sugg_dataset = load_dataset("s-nlp/paradetox")
    sugg_dataset = sugg_dataset['train'].train_test_split(test_size=0.2)
except Exception as e:
    print(f"Error loading ParaDetox dataset: {e}")
    raise

# Verify dataset columns
print("Suggestion dataset columns:", sugg_dataset['train'].column_names)

# Tokenizer and Model (BART for seq2seq)
sugg_model_name = "facebook/bart-base"
sugg_tokenizer = AutoTokenizer.from_pretrained(sugg_model_name)

def sugg_preprocess(examples):
    inputs = [f"detoxify: {text}" for text in examples['toxic_sentence']]
    model_inputs = sugg_tokenizer(inputs, max_length=128, truncation=True, padding=True)
    labels = sugg_tokenizer(examples['neutral_sentence'], max_length=128, truncation=True, padding=True)["input_ids"]
    model_inputs["labels"] = labels
    return model_inputs

sugg_tokenized = sugg_dataset.map(sugg_preprocess, batched=True)

# LoRA Config for Seq2Seq
sugg_lora_config = LoraConfig(
    r=8,
    lora_alpha=16,
    target_modules=["q_proj", "v_proj"],
    lora_dropout=0.1,
    bias="none",
    task_type="SEQ_2_SEQ_LM"
)

# Load model without quantization
try:
    sugg_model = AutoModelForSeq2SeqLM.from_pretrained(
        sugg_model_name,
        torch_dtype=torch.float16,
        device_map="auto"
    )
except Exception as e:
    print(f"Error loading suggestion model: {e}")
    raise
sugg_model = get_peft_model(sugg_model, sugg_lora_config)

# Training Args
sugg_training_args = TrainingArguments(
    output_dir="./sugg_results",
    eval_strategy="epoch",
    learning_rate=2e-5,
    per_device_train_batch_size=4,
    per_device_eval_batch_size=4,
    num_train_epochs=3,
    weight_decay=0.01,
    fp16=True,
    logging_steps=10,
    save_strategy="epoch",
    load_best_model_at_end=True,
    report_to="none",
    gradient_accumulation_steps=4,
    gradient_checkpointing=True
)

# Trainer
sugg_trainer = Trainer(
    model=sugg_model,
    args=sugg_training_args,
    train_dataset=sugg_tokenized["train"],
    eval_dataset=sugg_tokenized["test"],
    tokenizer=sugg_tokenizer
)

# Train Suggestion Model
print("Training Pre-Text Suggestion Model...")
try:
    sugg_trainer.train()
    sugg_trainer.save_model("./lora_suggestion_model")
except Exception as e:
    print(f"Error during suggestion training: {e}")
    raise

# --- Inference Function: Detect and Suggest ---
def pre_post_suggest(text):
    device = "cuda" if torch.cuda.is_available() else "cpu"
    # Detection
    det_inputs = det_tokenizer(text, return_tensors="pt", truncation=True).to(device)
    det_model.to(device)
    with torch.no_grad():
        det_outputs = det_model(**det_inputs)
    det_probs = torch.softmax(det_outputs.logits, dim=1)
    det_label_id = torch.argmax(det_probs).item()
    labels = ["hate speech", "offensive language", "neither"]
    det_conf = det_probs[0][det_label_id].item()
    det_label = labels[det_label_id]

    if det_label == "neither":
        return f"Post seems fine ({det_label}, conf: {det_conf:.2f}). Post as is: '{text}'"

    # Suggestion if abusive
    sugg_inputs = sugg_tokenizer(f"detoxify: {text}", return_tensors="pt", truncation=True).to(device)
    sugg_model.to(device)
    with torch.no_grad():
        sugg_outputs = sugg_model.generate(**sugg_inputs, max_length=128, num_beams=4)
    suggested = sugg_tokenizer.decode(sugg_outputs[0], skip_special_tokens=True)
    return f"Detected as {det_label} (conf: {det_conf:.2f}). Suggested: '{suggested}'"

# Examples
print(pre_post_suggest("This is a nice day!"))
print(pre_post_suggest("You are a total idiot and a bitch."))
print(pre_post_suggest("I hate this retard show."))

# Colab-ready script: LoRA fine-tune for pre/post emotion detection & suggestion
# Copy-paste into ONE Colab cell and run. Restart runtime if Colab asks after installs.

# --------------- 0) Install required libs (may require runtime restart) ---------------
!pip install -q "transformers[torch]" accelerate datasets scikit-learn pandas peft evaluate

# --------------- 1) Imports ---------------
import os
import io
import pandas as pd
import numpy as np
import torch
from datasets import Dataset, DatasetDict
from sklearn.model_selection import train_test_split
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer,
    DataCollatorWithPadding,
)
from peft import LoraConfig, get_peft_model, PeftModel
from google.colab import files

# --------------- 2) Config (change if you want) ---------------
DATA_PATH = "/mnt/data/labeled_data.csv"  # preferred path; will prompt to upload if not present
MODEL_CHECKPOINT = "distilbert-base-uncased"  # small & fast
OUTPUT_DIR = "./lora_results"
NUM_EPOCHS = 3
BATCH_SIZE = 8
LEARNING_RATE = 2e-5
SEED = 42
os.makedirs("/mnt/data", exist_ok=True)

# --------------- 3) Load dataset (upload if missing) ---------------
def ensure_dataset(path=DATA_PATH):
    if os.path.exists(path):
        print(f"Using dataset at: {path}")
        return path
    print(f"No file found at {path}. Please upload 'labeled_data.csv' now (file picker will open).")
    uploaded = files.upload()
    if len(uploaded) == 0:
        raise FileNotFoundError("No file uploaded. Please upload your labeled_data.csv.")
    # Save the first uploaded file to DATA_PATH
    fname = list(uploaded.keys())[0]
    df = pd.read_csv(io.BytesIO(uploaded[fname]))
    df.to_csv(path, index=False)
    print(f"Uploaded and saved to {path}")
    return path

DATA_PATH = ensure_dataset(DATA_PATH)

# --------------- 4) Read and auto-detect columns ---------------
df = pd.read_csv(DATA_PATH)
print("Loaded dataset shape:", df.shape)
print("Columns:", df.columns.tolist())

# Heuristics to find text and label columns
def detect_text_label_cols(df):
    text_candidates = [c for c in df.columns if c.lower() in ("text","tweet","post","content","comment","message")]
    if not text_candidates:
        # fallback: first object/string column
        for c in df.columns:
            if df[c].dtype == object:
                text_candidates = [c]; break
    label_candidates = [c for c in df.columns if c.lower() in ("label","labels","target","emotion","class","category")]
    if not label_candidates:
        # fallback: any non-text column
        label_candidates = [c for c in df.columns if c not in text_candidates]
    if len(text_candidates)==0 or len(label_candidates)==0:
        raise ValueError("Could not auto-detect text/label columns. Please ensure CSV has text and label columns or rename them.")
    return text_candidates[0], label_candidates[0]  # prefer first of each

text_col, label_col = detect_text_label_cols(df)
print("Detected text column:", text_col)
print("Detected label column:", label_col)

# --------------- 5) Preprocess labels ---------------
# Support: single categorical label, numeric, or multi-label as comma-separated strings
raw_labels = df[label_col].fillna("").astype(str)
multi_label = False

if raw_labels.str.contains(",").any():
    # treat as multi-label comma separated
    multi_label = True
    from sklearn.preprocessing import MultiLabelBinarizer
    mlb = MultiLabelBinarizer()
    label_lists = raw_labels.apply(lambda x: [s.strip() for s in x.split(",") if s.strip()]).tolist()
    labels_matrix = mlb.fit_transform(label_lists)
    label_names = mlb.classes_.tolist()
    print("Detected multi-label with classes:", label_names)
    labels = labels_matrix
else:
    # single-label classification
    # if numeric-like -> use as ints; else map strings to ints
    try:
        maybe_ints = raw_labels.astype(int)
        labels = maybe_ints.values
        label_names = sorted(list(map(int, set(labels))))
        print("Detected numeric labels:", label_names)
    except:
        unique_vals = sorted(raw_labels.unique())
        label_map = {v:i for i,v in enumerate(unique_vals)}
        labels = raw_labels.map(label_map).astype(int).values
        label_names = unique_vals
        print("Detected string labels -> mapping:", label_map)

# --------------- 6) Build HF dataset and split ---------------
proc_df = pd.DataFrame({"text": df[text_col].astype(str).fillna("")})
if multi_label:
    # add labels as list
    proc_df["labels"] = labels.tolist()
else:
    proc_df["labels"] = labels.tolist()

hf = Dataset.from_pandas(proc_df)
if multi_label:
    split = hf.train_test_split(test_size=0.15, seed=SEED)
else:
    # stratify by labels using sklearn split then convert
    train_idx, val_idx = train_test_split(np.arange(len(hf)), test_size=0.15, random_state=SEED, stratify=proc_df["labels"])
    train_ds = hf.select(list(train_idx))
    val_ds = hf.select(list(val_idx))
    split = DatasetDict({"train": train_ds, "test": val_ds})

raw_datasets = DatasetDict({"train": split["train"], "validation": split["test"]})
print(raw_datasets)

# --------------- 7) Tokenize ---------------
tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)

def tokenize_fn(batch):
    return tokenizer(batch["text"], truncation=True, padding=True)

tokenized = raw_datasets.map(tokenize_fn, batched=True)

# Ensure proper label format
if multi_label:
    # convert labels to floats (trainer expects tensors later)
    def cast_labels(ex):
        ex["labels"] = [float(x) for x in ex["labels"]]
        return ex
    tokenized = tokenized.map(cast_labels)
else:
    # labels already ints in 'labels'
    pass

# Keep only needed columns
columns_to_keep = ["input_ids", "attention_mask", "labels"]
cols = [c for c in tokenized["train"].column_names if c not in columns_to_keep]
if cols:
    tokenized = tokenized.remove_columns(cols)

tokenized.set_format(type="torch")
data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

# --------------- 8) Model + LoRA setup ---------------
if multi_label:
    num_labels = labels.shape[1]
else:
    num_labels = int(max(labels)) + 1 if np.max(labels) >= 1 else 2

print("num_labels =", num_labels)
base_model = AutoModelForSequenceClassification.from_pretrained(MODEL_CHECKPOINT, num_labels=num_labels)

lora_config = LoraConfig(
    r=8,
    lora_alpha=32,
    target_modules=["query", "key", "value"],
    lora_dropout=0.1,
    bias="none",
    task_type="SEQ_CLS",
)
model = get_peft_model(base_model, lora_config)

# Print parameter counts
trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)
total = sum(p.numel() for p in model.parameters())
print(f"Trainable params: {trainable:,} | Total params: {total:,}")

# --------------- 9) Metrics ---------------
import numpy as np
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score

def compute_metrics(eval_pred):
    logits, labels_batch = eval_pred
    if multi_label:
        probs = torch.sigmoid(torch.from_numpy(logits))
        preds = (probs >= 0.5).long().numpy()
        labels_np = np.array(labels_batch, dtype=int)
        f1 = f1_score(labels_np, preds, average="micro", zero_division=0)
        acc = (labels_np == preds).mean()
        return {"f1_micro": float(f1), "accuracy": float(acc)}
    else:
        preds = np.argmax(logits, axis=-1)
        acc = accuracy_score(labels_batch, preds)
        precision = precision_score(labels_batch, preds, average="macro", zero_division=0)
        recall = recall_score(labels_batch, preds, average="macro", zero_division=0)
        f1 = f1_score(labels_batch, preds, average="macro", zero_division=0)
        return {"accuracy": float(acc), "precision_macro": float(precision), "recall_macro": float(recall), "f1_macro": float(f1)}

# --------------- 10) TrainingArguments and Trainer ---------------
training_args = TrainingArguments(
    output_dir=OUTPUT_DIR,
    evaluation_strategy="epoch",
    save_strategy="epoch",
    per_device_train_batch_size=BATCH_SIZE,
    per_device_eval_batch_size=BATCH_SIZE,
    num_train_epochs=NUM_EPOCHS,
    learning_rate=LEARNING_RATE,
    weight_decay=0.01,
    logging_dir="./logs",
    logging_steps=20,
    seed=SEED,
    load_best_model_at_end=True,
    metric_for_best_model="f1_micro" if multi_label else "f1_macro",
    greater_is_better=True,
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized["train"],
    eval_dataset=tokenized["validation"],
    tokenizer=tokenizer,
    data_collator=data_collator,
    compute_metrics=compute_metrics,
)

# --------------- 11) Train ---------------
print("Starting training... (this may take a few minutes)")
trainer.train()

# --------------- 12) Save adapter and tokenizer ---------------
os.makedirs(OUTPUT_DIR, exist_ok=True)
model.save_pretrained(os.path.join(OUTPUT_DIR, "lora_adapter"))
tokenizer.save_pretrained(os.path.join(OUTPUT_DIR, "tokenizer"))
print("Saved LoRA adapter to:", os.path.join(OUTPUT_DIR, "lora_adapter"))

# --------------- 13) Simple inference using the saved adapter ---------------
# Reload base + adapter for inference (safe pattern)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
base_for_infer = AutoModelForSequenceClassification.from_pretrained(MODEL_CHECKPOINT, num_labels=num_labels)
peft_model = PeftModel.from_pretrained(base_for_infer, os.path.join(OUTPUT_DIR, "lora_adapter"))
peft_model.to(device)
peft_model.eval()

sample_texts = [
    "I love this post â€” it made my day!",
    "I feel so upset and angry after reading this.",
    "Not sure how to respond to this post."
]
inputs = tokenizer(sample_texts, truncation=True, padding=True, return_tensors="pt")
inputs = {k: v.to(device) for k,v in inputs.items()}

with torch.no_grad():
    outputs = peft_model(**inputs)
    logits = outputs.logits
    if multi_label:
        probs = torch.sigmoid(logits).cpu().numpy()
        preds = (probs >= 0.5).astype(int)
        print("Multi-label probabilities:\n", probs)
        print("Preds (0/1):\n", preds)
    else:
        probs = torch.nn.functional.softmax(logits, dim=-1).cpu().numpy()
        preds = probs.argmax(axis=-1)
        print("Predictions:", preds)
        print("Probabilities:", probs)

print("Done. LoRA adapter saved at:", os.path.join(OUTPUT_DIR, "lora_adapter"))

# Colab-ready script: LoRA fine-tune for pre/post emotion detection & suggestion
# Copy-paste into ONE Colab cell and run. Restart runtime if Colab asks after installs.

# --------------- 0) Install required libs (may require runtime restart) ---------------
!pip install -q "transformers[torch]" accelerate datasets scikit-learn pandas peft evaluate

# --------------- 1) Imports ---------------
import os
import io
import pandas as pd
import numpy as np
import torch
from datasets import Dataset, DatasetDict
from sklearn.model_selection import train_test_split
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer,
    DataCollatorWithPadding,
)
from peft import LoraConfig, get_peft_model, PeftModel
from google.colab import files

# --------------- 2) Config (adjust if you want) ---------------
DATA_PATH = "/mnt/data/labeled_data.csv"   # preferred path; will prompt to upload if missing
MODEL_CHECKPOINT = "distilbert-base-uncased"  # small & fast for Colab; change to roberta-base if you prefer
OUTPUT_DIR = "./lora_results"
NUM_EPOCHS = 3
BATCH_SIZE = 8
LEARNING_RATE = 2e-5
SEED = 42
os.makedirs("/mnt/data", exist_ok=True)
os.makedirs(OUTPUT_DIR, exist_ok=True)

# --------------- 3) Load dataset (upload if missing) ---------------
def ensure_dataset(path=DATA_PATH):
    if os.path.exists(path):
        print(f"Using dataset at: {path}")
        return path
    print(f"No file found at {path}. Please upload 'labeled_data.csv' now (file picker will open).")
    uploaded = files.upload()
    if len(uploaded) == 0:
        raise FileNotFoundError("No file uploaded. Please upload your labeled_data.csv.")
    fname = list(uploaded.keys())[0]
    df = pd.read_csv(io.BytesIO(uploaded[fname]))
    df.to_csv(path, index=False)
    print(f"Uploaded and saved to {path}")
    return path

DATA_PATH = ensure_dataset(DATA_PATH)

# --------------- 4) Read and auto-detect columns ---------------
df = pd.read_csv(DATA_PATH)
print("Loaded dataset shape:", df.shape)
print("Columns:", df.columns.tolist())

def detect_text_label_cols(df):
    text_candidates = [c for c in df.columns if c.lower() in ("text","tweet","post","content","comment","message")]
    if not text_candidates:
        for c in df.columns:
            if df[c].dtype == object:
                text_candidates = [c]; break
    label_candidates = [c for c in df.columns if c.lower() in ("label","labels","target","emotion","class","category","sentiment","suggestion")]
    if not label_candidates:
        label_candidates = [c for c in df.columns if c not in text_candidates]
    if len(text_candidates)==0 or len(label_candidates)==0:
        raise ValueError("Could not auto-detect text/label columns. Rename CSV columns to 'text' and 'label' or provide names explicitly.")
    return text_candidates[0], label_candidates[0]

text_col, label_col = detect_text_label_cols(df)
print("Detected text column:", text_col)
print("Detected label column:", label_col)

# --------------- 5) Preprocess labels ---------------
raw_labels = df[label_col].fillna("").astype(str)
multi_label = False

if raw_labels.str.contains(",").any():
    # multi-label (comma-separated)
    multi_label = True
    from sklearn.preprocessing import MultiLabelBinarizer
    mlb = MultiLabelBinarizer()
    label_lists = raw_labels.apply(lambda x: [s.strip() for s in x.split(",") if s.strip()]).tolist()
    labels_matrix = mlb.fit_transform(label_lists)
    label_names = mlb.classes_.tolist()
    print("Detected multi-label with classes:", label_names)
    labels = labels_matrix
else:
    # single-label (try numeric then strings)
    try:
        maybe_ints = raw_labels.astype(int)
        labels = maybe_ints.values
        label_names = sorted(list(map(int, set(labels))))
        print("Detected numeric labels:", label_names)
    except:
        unique_vals = sorted([v for v in raw_labels.unique() if v!=""])
        # handle empty label strings by mapping to 0 if present
        if "" in raw_labels.unique():
            unique_vals.append("")
        label_map = {v:i for i,v in enumerate(unique_vals)}
        labels = raw_labels.map(lambda x: label_map[x] if x in label_map else 0).astype(int).values
        label_names = unique_vals
        print("Detected string labels -> mapping:", label_map)

# --------------- 6) Build HF dataset and split ---------------
proc_df = pd.DataFrame({"text": df[text_col].astype(str).fillna("")})
proc_df["labels"] = labels.tolist()

hf = Dataset.from_pandas(proc_df)
if multi_label:
    split = hf.train_test_split(test_size=0.15, seed=SEED)
else:
    # stratified split for single-label
    train_idx, val_idx = train_test_split(np.arange(len(hf)), test_size=0.15, random_state=SEED, stratify=proc_df["labels"])
    train_ds = hf.select(list(train_idx))
    val_ds = hf.select(list(val_idx))
    split = DatasetDict({"train": train_ds, "test": val_ds})

raw_datasets = DatasetDict({"train": split["train"], "validation": split["test"]})
print(raw_datasets)

# --------------- 7) Tokenize ---------------
tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)

def tokenize_fn(batch):
    return tokenizer(batch["text"], truncation=True, padding=True)

tokenized = raw_datasets.map(tokenize_fn, batched=True)

if multi_label:
    def cast_labels(ex):
        ex["labels"] = [float(x) for x in ex["labels"]]
        return ex
    tokenized = tokenized.map(cast_labels)

# Keep only required columns
required = ["input_ids", "attention_mask", "labels"]
cols_to_rm = [c for c in tokenized["train"].column_names if c not in required]
if cols_to_rm:
    tokenized = tokenized.remove_columns(cols_to_rm)

tokenized.set_format(type="torch")
data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

# --------------- 8) Model + LoRA setup (automatic target modules selection) ---------------
if multi_label:
    num_labels = labels.shape[1]
else:
    num_labels = int(max(labels)) + 1 if np.max(labels) >= 1 else 2

print("num_labels =", num_labels)
base_model = AutoModelForSequenceClassification.from_pretrained(MODEL_CHECKPOINT, num_labels=num_labels)

# Automatic selection of target modules by inspecting model_type
model_type = getattr(base_model.config, "model_type", "").lower()
print("Detected model_type:", model_type)

if "distilbert" in model_type or "distil" in MODEL_CHECKPOINT:
    target_modules = ["q_lin", "k_lin", "v_lin", "out_lin"]
elif "bert" in model_type or "roberta" in model_type or "albert" in model_type:
    # BERT/Roberta use query/key/value naming in attention layers
    target_modules = ["query", "key", "value", "dense"]
elif "electra" in model_type:
    target_modules = ["query", "key", "value", "dense"]
else:
    # safe default
    target_modules = ["query", "key", "value"]

print("Using LoRA target modules:", target_modules)

lora_config = LoraConfig(
    r=8,
    lora_alpha=32,
    target_modules=target_modules,
    lora_dropout=0.1,
    bias="none",
    task_type="SEQ_CLS",  # works for classification
)

# Try inject LoRA, but provide debug info if it fails
try:
    model = get_peft_model(base_model, lora_config)
except ValueError as e:
    print("PEFT injection failed with error:", e)
    # Print available module names containing likely substrings to help debug
    print("\nCandidate module names in model (filtered):")
    names = set()
    for n, m in base_model.named_modules():
        # filter out trivial/empty names
        if n and any(k in n.lower() for k in ["q", "k", "v", "attn", "key", "query", "value", "lin", "dense", "out"]):
            names.add(n)
    for n in sorted(names):
        print("  ", n)
    raise

# Print parameter counts
trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)
total = sum(p.numel() for p in model.parameters())
print(f"Trainable params: {trainable:,} | Total params: {total:,}")

# --------------- 9) Metrics ---------------
import numpy as np
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score

def compute_metrics(eval_pred):
    logits, labels_batch = eval_pred
    if multi_label:
        probs = torch.sigmoid(torch.from_numpy(logits))
        preds = (probs >= 0.5).long().numpy()
        labels_np = np.array(labels_batch, dtype=int)
        f1 = f1_score(labels_np, preds, average="micro", zero_division=0)
        acc = (labels_np == preds).mean()
        return {"f1_micro": float(f1), "accuracy": float(acc)}
    else:
        preds = np.argmax(logits, axis=-1)
        acc = accuracy_score(labels_batch, preds)
        precision = precision_score(labels_batch, preds, average="macro", zero_division=0)
        recall = recall_score(labels_batch, preds, average="macro", zero_division=0)
        f1 = f1_score(labels_batch, preds, average="macro", zero_division=0)
        return {"accuracy": float(acc), "precision_macro": float(precision), "recall_macro": float(recall), "f1_macro": float(f1)}

# --------------- 10) TrainingArguments and Trainer ---------------
training_args = TrainingArguments(
    output_dir=OUTPUT_DIR,
    evaluation_strategy="epoch",
    save_strategy="epoch",
    per_device_train_batch_size=BATCH_SIZE,
    per_device_eval_batch_size=BATCH_SIZE,
    num_train_epochs=NUM_EPOCHS,
    learning_rate=LEARNING_RATE,
    weight_decay=0.01,
    logging_dir="./logs",
    logging_steps=20,
    seed=SEED,
    load_best_model_at_end=True,
    metric_for_best_model="f1_micro" if multi_label else "f1_macro",
    greater_is_better=True,
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized["train"],
    eval_dataset=tokenized["validation"],
    tokenizer=tokenizer,
    data_collator=data_collator,
    compute_metrics=compute_metrics,
)

# --------------- 11) Train ---------------
print("Starting training... (this may take a few minutes)")
trainer.train()

# --------------- 12) Save adapter and tokenizer ---------------
model.save_pretrained(os.path.join(OUTPUT_DIR, "lora_adapter"))
tokenizer.save_pretrained(os.path.join(OUTPUT_DIR, "tokenizer"))
print("Saved LoRA adapter to:", os.path.join(OUTPUT_DIR, "lora_adapter"))

# --------------- 13) Simple inference using the saved adapter ---------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
base_for_infer = AutoModelForSequenceClassification.from_pretrained(MODEL_CHECKPOINT, num_labels=num_labels)
peft_model = PeftModel.from_pretrained(base_for_infer, os.path.join(OUTPUT_DIR, "lora_adapter"))
peft_model.to(device)
peft_model.eval()

sample_texts = [
    "I love this post â€” it made my day!",
    "I feel so upset and angry after reading this.",
    "Not sure how to respond to this post."
]
inputs = tokenizer(sample_texts, truncation=True, padding=True, return_tensors="pt")
inputs = {k: v.to(device) for k,v in inputs.items()}

with torch.no_grad():
    outputs = peft_model(**inputs)
    logits = outputs.logits
    if multi_label:
        probs = torch.sigmoid(logits).cpu().numpy()
        preds = (probs >= 0.5).astype(int)
        print("Multi-label probabilities:\n", probs)
        print("Preds (0/1):\n", preds)
    else:
        probs = torch.nn.functional.softmax(logits, dim=-1).cpu().numpy()
        preds = probs.argmax(axis=-1)
        print("Predictions:", preds)
        print("Probabilities:", probs)

print("Done. LoRA adapter saved at:", os.path.join(OUTPUT_DIR, "lora_adapter"))

# Colab-ready script: LoRA fine-tune for pre/post emotion detection & suggestion
# Copy-paste into ONE Colab cell and run. Restart runtime if Colab asks after installs.

# --------------- 0) Install required libs (may require runtime restart) ---------------
!pip install -q "transformers[torch]" accelerate datasets scikit-learn pandas peft evaluate

# --------------- 1) Imports ---------------
import os
import io
import pandas as pd
import numpy as np
import torch
from datasets import Dataset, DatasetDict
from sklearn.model_selection import train_test_split
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer,
    DataCollatorWithPadding,
)
from peft import LoraConfig, get_peft_model, PeftModel
from google.colab import files

# --------------- 2) Config (adjust if you want) ---------------
DATA_PATH = "/mnt/data/labeled_data.csv"   # preferred path; will prompt to upload if missing
MODEL_CHECKPOINT = "distilbert-base-uncased"  # small & fast for Colab; change to roberta-base if you prefer
OUTPUT_DIR = "./lora_results"
NUM_EPOCHS = 3
BATCH_SIZE = 8
LEARNING_RATE = 2e-5
SEED = 42
os.makedirs("/mnt/data", exist_ok=True)
os.makedirs(OUTPUT_DIR, exist_ok=True)

# --------------- 3) Load dataset (upload if missing) ---------------
def ensure_dataset(path=DATA_PATH):
    if os.path.exists(path):
        print(f"Using dataset at: {path}")
        return path
    print(f"No file found at {path}. Please upload 'labeled_data.csv' now (file picker will open).")
    uploaded = files.upload()
    if len(uploaded) == 0:
        raise FileNotFoundError("No file uploaded. Please upload your labeled_data.csv.")
    fname = list(uploaded.keys())[0]
    df = pd.read_csv(io.BytesIO(uploaded[fname]))
    df.to_csv(path, index=False)
    print(f"Uploaded and saved to {path}")
    return path

DATA_PATH = ensure_dataset(DATA_PATH)

# --------------- 4) Read and auto-detect columns ---------------
df = pd.read_csv(DATA_PATH)
print("Loaded dataset shape:", df.shape)
print("Columns:", df.columns.tolist())

def detect_text_label_cols(df):
    text_candidates = [c for c in df.columns if c.lower() in ("text","tweet","post","content","comment","message")]
    if not text_candidates:
        for c in df.columns:
            if df[c].dtype == object:
                text_candidates = [c]; break
    label_candidates = [c for c in df.columns if c.lower() in ("label","labels","target","emotion","class","category","sentiment","suggestion")]
    if not label_candidates:
        label_candidates = [c for c in df.columns if c not in text_candidates]
    if len(text_candidates)==0 or len(label_candidates)==0:
        raise ValueError("Could not auto-detect text/label columns. Rename CSV columns to 'text' and 'label' or provide names explicitly.")
    return text_candidates[0], label_candidates[0]

text_col, label_col = detect_text_label_cols(df)
print("Detected text column:", text_col)
print("Detected label column:", label_col)

# --------------- 5) Preprocess labels ---------------
raw_labels = df[label_col].fillna("").astype(str)
multi_label = False

if raw_labels.str.contains(",").any():
    # multi-label (comma-separated)
    multi_label = True
    from sklearn.preprocessing import MultiLabelBinarizer
    mlb = MultiLabelBinarizer()
    label_lists = raw_labels.apply(lambda x: [s.strip() for s in x.split(",") if s.strip()]).tolist()
    labels_matrix = mlb.fit_transform(label_lists)
    label_names = mlb.classes_.tolist()
    print("Detected multi-label with classes:", label_names)
    labels = labels_matrix
else:
    # single-label (try numeric then strings)
    try:
        maybe_ints = raw_labels.astype(int)
        labels = maybe_ints.values
        label_names = sorted(list(map(int, set(labels))))
        print("Detected numeric labels:", label_names)
    except:
        unique_vals = sorted([v for v in raw_labels.unique() if v!=""])
        if "" in raw_labels.unique():
            unique_vals.append("")
        label_map = {v:i for i,v in enumerate(unique_vals)}
        labels = raw_labels.map(lambda x: label_map[x] if x in label_map else 0).astype(int).values
        label_names = unique_vals
        print("Detected string labels -> mapping:", label_map)

# --------------- 6) Build HF dataset and split ---------------
proc_df = pd.DataFrame({"text": df[text_col].astype(str).fillna("")})
proc_df["labels"] = labels.tolist()

hf = Dataset.from_pandas(proc_df)
if multi_label:
    split = hf.train_test_split(test_size=0.15, seed=SEED)
else:
    # stratified split for single-label
    train_idx, val_idx = train_test_split(np.arange(len(hf)), test_size=0.15, random_state=SEED, stratify=proc_df["labels"])
    train_ds = hf.select(list(train_idx))
    val_ds = hf.select(list(val_idx))
    split = DatasetDict({"train": train_ds, "test": val_ds})

raw_datasets = DatasetDict({"train": split["train"], "validation": split["test"]})
print(raw_datasets)

# --------------- 7) Tokenize ---------------
tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)

def tokenize_fn(batch):
    return tokenizer(batch["text"], truncation=True, padding=True)

tokenized = raw_datasets.map(tokenize_fn, batched=True)

if multi_label:
    def cast_labels(ex):
        ex["labels"] = [float(x) for x in ex["labels"]]
        return ex
    tokenized = tokenized.map(cast_labels)

# Keep only required columns
required = ["input_ids", "attention_mask", "labels"]
cols_to_rm = [c for c in tokenized["train"].column_names if c not in required]
if cols_to_rm:
    tokenized = tokenized.remove_columns(cols_to_rm)

tokenized.set_format(type="torch")
data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

# --------------- 8) Model + LoRA setup (automatic target modules selection) ---------------
if multi_label:
    num_labels = labels.shape[1]
else:
    num_labels = int(max(labels)) + 1 if np.max(labels) >= 1 else 2

print("num_labels =", num_labels)
base_model = AutoModelForSequenceClassification.from_pretrained(MODEL_CHECKPOINT, num_labels=num_labels)

# Automatic selection of target modules by inspecting model_type
model_type = getattr(base_model.config, "model_type", "").lower()
print("Detected model_type:", model_type)

if "distilbert" in model_type or "distil" in MODEL_CHECKPOINT:
    target_modules = ["q_lin", "k_lin", "v_lin", "out_lin"]
elif "bert" in model_type or "roberta" in model_type or "albert" in model_type:
    target_modules = ["query", "key", "value", "dense"]
elif "electra" in model_type:
    target_modules = ["query", "key", "value", "dense"]
else:
    target_modules = ["query", "key", "value"]

print("Using LoRA target modules:", target_modules)

lora_config = LoraConfig(
    r=8,
    lora_alpha=32,
    target_modules=target_modules,
    lora_dropout=0.1,
    bias="none",
    task_type="SEQ_CLS",
)

try:
    model = get_peft_model(base_model, lora_config)
except ValueError as e:
    print("PEFT injection failed with error:", e)
    print("\nCandidate module names in model (filtered):")
    names = set()
    for n, m in base_model.named_modules():
        if n and any(k in n.lower() for k in ["q", "k", "v", "attn", "key", "query", "value", "lin", "dense", "out"]):
            names.add(n)
    for n in sorted(names):
        print("  ", n)
    raise

# Print parameter counts
trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)
total = sum(p.numel() for p in model.parameters())
print(f"Trainable params: {trainable:,} | Total params: {total:,}")

# --------------- 9) Metrics ---------------
import numpy as np
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score

def compute_metrics(eval_pred):
    logits, labels_batch = eval_pred
    if multi_label:
        probs = torch.sigmoid(torch.from_numpy(logits))
        preds = (probs >= 0.5).long().numpy()
        labels_np = np.array(labels_batch, dtype=int)
        f1 = f1_score(labels_np, preds, average="micro", zero_division=0)
        acc = (labels_np == preds).mean()
        return {"f1_micro": float(f1), "accuracy": float(acc)}
    else:
        preds = np.argmax(logits, axis=-1)
        acc = accuracy_score(labels_batch, preds)
        precision = precision_score(labels_batch, preds, average="macro", zero_division=0)
        recall = recall_score(labels_batch, preds, average="macro", zero_division=0)
        f1 = f1_score(labels_batch, preds, average="macro", zero_division=0)
        return {"accuracy": float(acc), "precision_macro": float(precision), "recall_macro": float(recall), "f1_macro": float(f1)}

# --------------- 10) TrainingArguments and Trainer ---------------
# Create TrainingArguments robustly to support multiple transformers versions
try:
    training_args = TrainingArguments(
        output_dir=OUTPUT_DIR,
        evaluation_strategy="epoch",
        save_strategy="epoch",
        per_device_train_batch_size=BATCH_SIZE,
        per_device_eval_batch_size=BATCH_SIZE,
        num_train_epochs=NUM_EPOCHS,
        learning_rate=LEARNING_RATE,
        weight_decay=0.01,
        logging_dir="./logs",
        logging_steps=20,
        seed=SEED,
        load_best_model_at_end=True,
        metric_for_best_model="f1_micro" if multi_label else "f1_macro",
        greater_is_better=True,
    )
except TypeError as te:
    # Fallback: construct with fewer kwargs then set attributes
    print("TrainingArguments constructor rejected some kwargs, falling back. Error:", te)
    training_args = TrainingArguments(
        output_dir=OUTPUT_DIR,
        per_device_train_batch_size=BATCH_SIZE,
        per_device_eval_batch_size=BATCH_SIZE,
        num_train_epochs=NUM_EPOCHS,
        learning_rate=LEARNING_RATE,
        weight_decay=0.01,
        logging_dir="./logs",
        seed=SEED,
    )
    # set commonly used attributes explicitly (works for most TF versions)
    try:
        training_args.evaluation_strategy = "epoch"
        training_args.save_strategy = "epoch"
    except Exception:
        # if attributes are not present, Trainer will still accept and use defaults
        pass
    training_args.load_best_model_at_end = True
    training_args.metric_for_best_model = "f1_micro" if multi_label else "f1_macro"
    training_args.greater_is_better = True

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized["train"],
    eval_dataset=tokenized["validation"],
    tokenizer=tokenizer,
    data_collator=data_collator,
    compute_metrics=compute_metrics,
)

# --------------- 11) Train ---------------
print("Starting training... (this may take a few minutes)")
trainer.train()

# --------------- 12) Save adapter and tokenizer ---------------
model.save_pretrained(os.path.join(OUTPUT_DIR, "lora_adapter"))
tokenizer.save_pretrained(os.path.join(OUTPUT_DIR, "tokenizer"))
print("Saved LoRA adapter to:", os.path.join(OUTPUT_DIR, "lora_adapter"))

# --------------- 13) Simple inference using the saved adapter ---------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
base_for_infer = AutoModelForSequenceClassification.from_pretrained(MODEL_CHECKPOINT, num_labels=num_labels)
peft_model = PeftModel.from_pretrained(base_for_infer, os.path.join(OUTPUT_DIR, "lora_adapter"))
peft_model.to(device)
peft_model.eval()

sample_texts = [
    "I love this post â€” it made my day!",
    "I feel so upset and angry after reading this.",
    "Not sure how to respond to this post."
]
inputs = tokenizer(sample_texts, truncation=True, padding=True, return_tensors="pt")
inputs = {k: v.to(device) for k,v in inputs.items()}

with torch.no_grad():
    outputs = peft_model(**inputs)
    logits = outputs.logits
    if multi_label:
        probs = torch.sigmoid(logits).cpu().numpy()
        preds = (probs >= 0.5).astype(int)
        print("Multi-label probabilities:\n", probs)
        print("Preds (0/1):\n", preds)
    else:
        probs = torch.nn.functional.softmax(logits, dim=-1).cpu().numpy()
        preds = probs.argmax(axis=-1)
        print("Predictions:", preds)
        print("Probabilities:", probs)

print("Done. LoRA adapter saved at:", os.path.join(OUTPUT_DIR, "lora_adapter"))

# Complete Colab-ready script to finetune LoRA adapter for SmolLM2
# Run this cell-by-cell in Colab.

# 0) Install dependencies
!pip install -q --upgrade pip
# core libraries
!pip install -q transformers datasets accelerate peft bitsandbytes sentencepiece evaluate scikit-learn==1.2.2 safetensors

# 1) Imports
import os
import random
import json
import math
from pathlib import Path
from typing import Dict, List, Union

import numpy as np
import pandas as pd
import torch
from datasets import Dataset, load_metric
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_recall_fscore_support, accuracy_score

from transformers import (
    AutoTokenizer,
    AutoModelForCausalLM,
    Trainer,
    TrainingArguments,
    DataCollatorForLanguageModeling,
    DataCollatorForSeq2Seq,
)

from peft import (
    get_peft_model,
    LoraConfig,
    TaskType,
    prepare_model_for_kbit_training,
)

# 2) Helper: upload file in Colab (run only if you need to upload manually)
# from google.colab import files
# uploaded = files.upload()  # upload labeled_data.csv into runtime

# 3) Load CSV
CSV_PATH = "labeled_data.csv"
if not os.path.exists(CSV_PATH):
    raise FileNotFoundError(f"Please upload '{CSV_PATH}' to the Colab runtime (left Files pane).")

df = pd.read_csv(CSV_PATH, dtype=str).fillna("")
print("CSV loaded, shape:", df.shape)
display(df.head())

# 4) Infer label for each row
# The CSV is expected to have columns:
# - count, hate_speech, offensive_language, neither, class, tweet
# We'll create a normalized label column 'label' with values: 'hate_speech', 'offensive_language', 'neither'

def infer_label(row):
    # If tweet empty -> skip later
    # Case 1: one-hot columns present with '1' or 'True' etc.
    one_hot_cols = ['hate_speech', 'offensive_language', 'neither']
    present_cols = [c for c in one_hot_cols if c in row.index]
    # check one-hot numeric-like values
    if present_cols:
        for c in present_cols:
            val = row[c]
            if str(val).strip() in ("1", "True", "true", "yes", "Y", "y"):
                return c
        # fallthrough: maybe they are probabilities or labels not set
    # Case 2: 'class' column may contain label names or numeric codes
    if 'class' in row.index:
        cval = str(row['class']).strip()
        if cval.lower() in ("hate_speech", "offensive_language", "neither"):
            return cval.lower()
        # if numeric like 0/1/2 -> map using available one_hot columns if present
        if cval.isdigit():
            # try to map using one_hot columns if any of them have '1'
            for c in present_cols:
                if str(row[c]).strip() in ("1", "True", "true", "yes", "Y", "y"):
                    return c
            # fallback numeric mapping guess: 0->hate,1->offensive,2->neither
            mapping = {"0":"hate_speech","1":"offensive_language","2":"neither"}
            if cval in mapping:
                return mapping[cval]
    # default: if nothing else, try simple keyword search in tweet
    tw = str(row.get('tweet',"")).lower()
    if any(x in tw for x in ["hate", "kill", "racist", "nazi", "slur", "genocide"]):
        return "hate_speech"
    if any(x in tw for x in ["stupid", "idiot", "jerk", "shut up", "screw you"]):
        return "offensive_language"
    return "neither"

df['label'] = df.apply(infer_label, axis=1)
print("Label counts:")
print(df['label'].value_counts())

# 5) Build instruction-completion pairs
# We'll create short template completions per label so model learns both classification label and a short warning/info.
TEMPLATE = {
    "hate_speech": {
        "label": "Hate speech",
        "warning": "Warning: This post includes language targeting a protected group and may incite hatred. Consider removing it and educating the author."
    },
    "offensive_language": {
        "label": "Offensive language",
        "warning": "Info: This post contains abusive or offensive language. Consider warning the user and reviewing community guidelines."
    },
    "neither": {
        "label": "Neutral / No violation",
        "warning": "Info: This post appears neutral and does not violate policy."
    }
}

def make_example(row):
    tweet = str(row.get('tweet',"")).strip()
    label = row.get('label',"neither")
    # instruction for the model - short SFT style
    instruction = (
        "Analyze the following social media post. Output a short classification label and a brief warning or information message "
        "explaining the issue and suggested action. Keep the response <= 50 words.\n\n"
        f"Post: \"{tweet}\"\n\n"
        "Output format (exactly):\nLabel: <one of: Hate speech | Offensive language | Neutral / No violation>\nMessage: <short message>"
    )
    template = TEMPLATE.get(label, TEMPLATE['neither'])
    completion = f"Label: {template['label']}\nMessage: {template['warning']}"
    # We don't include instruction in the target (standard SFT), but many prefer including both. We'll use instruction as input and completion as target.
    return {"instruction": instruction, "completion": completion, "raw_label": label, "tweet": tweet}

examples = [make_example(r) for _, r in df.iterrows() if str(r.get('tweet',"")).strip() != ""]
data_df = pd.DataFrame(examples)
print("Prepared examples:", len(data_df))
display(data_df.sample(min(5,len(data_df))))

# 6) Train/validation split
train_df, val_df = train_test_split(data_df, test_size=0.1, random_state=42, stratify=data_df['raw_label'] if len(data_df)>1 else None)
train_ds = Dataset.from_pandas(train_df.reset_index(drop=True))
val_ds = Dataset.from_pandas(val_df.reset_index(drop=True))
print("Train/Val sizes:", len(train_ds), len(val_ds))

# 7) Choose base model (SmolLM2 small or 360M recommended on Colab)
# If you have a GPU with enough memory, pick a larger variant.
BASE_MODEL = "unsloth/SmolLM2-360M"  # change to a different SmolLM2 variant if you prefer
# alternate examples: "HuggingFaceTB/SmolLM2-1.7B-Instruct-16k" (bigger)

# 8) Load tokenizer and model (try 8-bit to reduce memory)
print("Loading tokenizer and model:", BASE_MODEL)
tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, use_fast=False)
# ensure tokenizer has pad token (for Trainer)
if tokenizer.pad_token_id is None:
    tokenizer.add_special_tokens({'pad_token':'<pad>'})

# Load model with bitsandbytes if available to save memory. If this errors, remove load_in_8bit and device_map.
try:
    model = AutoModelForCausalLM.from_pretrained(
        BASE_MODEL,
        load_in_8bit=True,
        device_map="auto",
        use_safetensors=True,
    )
    print("Loaded model in 8-bit.")
except Exception as e:
    print("Could not load in 8-bit; falling back to fp16/auto. Error:", e)
    model = AutoModelForCausalLM.from_pretrained(BASE_MODEL, device_map="auto")
    # optionally convert to half
    try:
        model.half()
    except:
        pass

# 9) Prepare model for kbit training (PEFT best practice)
model = prepare_model_for_kbit_training(model)

# 10) Setup LoRA config
lora_r = 8
lora_alpha = 16
target_modules = ["q_proj", "k_proj", "v_proj", "o_proj"]  # typical transformer modules; it's okay if some don't exist
peft_config = LoraConfig(
    task_type=TaskType.CAUSAL_LM,
    inference_mode=False,
    r=lora_r,
    lora_alpha=lora_alpha,
    target_modules=target_modules,
    lora_dropout=0.05,
)

model = get_peft_model(model, peft_config)
model.print_trainable_parameters()

# 11) Tokenization function: format instruction + completion for causal LM
max_length = 512

def preprocess_function(examples):
    inputs = [ins for ins in examples["instruction"]]
    targets = [tgt for tgt in examples["completion"]]
    # For causal LM we concatenate instruction + target and set labels to tokens of whole sequence,
    # but mask the instruction tokens to -100 so loss only computed on target tokens.
    input_ids = []
    labels = []
    for instr, tgt in zip(inputs, targets):
        # join with special separator (we'll just concatenate)
        full = instr + "\n\n" + tgt
        tok = tokenizer(full, truncation=True, max_length=max_length, padding='max_length')
        lbl = tok["input_ids"].copy()
        # mask the instruction tokens (set to -100) so loss only on completion
        instr_tok = tokenizer(instr, truncation=True, max_length=max_length, padding='max_length')
        instr_len = sum(1 for t in instr_tok["input_ids"] if t != tokenizer.pad_token_id)
        # But instr_tok has padding â€” better compute exact encoding length without padding:
        instr_enc = tokenizer(instr, truncation=True, max_length=max_length)["input_ids"]
        instr_len = len(instr_enc)
        # mask first instr_len tokens
        lbl = [-100]*instr_len + lbl[instr_len:]
        # pad/truncate labels to match tok length
        lbl = lbl[:max_length]
        if len(lbl) < max_length:
            lbl += [-100] * (max_length - len(lbl))
        input_ids.append(tok["input_ids"])
        labels.append(lbl)
    return {"input_ids": input_ids, "attention_mask": [[1 if id!=tokenizer.pad_token_id else 0 for id in seq] for seq in input_ids], "labels": labels}

# Convert datasets
train_encoded = train_ds.map(preprocess_function, batched=True, remove_columns=train_ds.column_names)
eval_encoded = val_ds.map(preprocess_function, batched=True, remove_columns=val_ds.column_names)

# 12) Data collator (for causal LM)
from transformers import DataCollatorForLanguageModeling

data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)

# 13) Training arguments
output_dir = "smollm2_lora_adapter"
training_args = TrainingArguments(
    output_dir=output_dir,
    per_device_train_batch_size=4,
    per_device_eval_batch_size=4,
    gradient_accumulation_steps=4,
    num_train_epochs=3,
    learning_rate=2e-4,
    fp16=True,
    logging_steps=10,
    evaluation_strategy="epoch",
    save_strategy="epoch",
    save_total_limit=2,
    remove_unused_columns=False,
    push_to_hub=False,
    report_to="none",
)

# 14) Create Trainer and run training
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_encoded,
    eval_dataset=eval_encoded,
    data_collator=lambda data: {
        "input_ids": torch.tensor([d["input_ids"] for d in data], dtype=torch.long),
        "attention_mask": torch.tensor([d["attention_mask"] for d in data], dtype=torch.long),
        "labels": torch.tensor([d["labels"] for d in data], dtype=torch.long),
    },
    tokenizer=tokenizer,
)

# Train
trainer.train()

# 15) Save LoRA adapter weights
adapter_dir = os.path.join(output_dir, "lora_adapter")
model.save_pretrained(adapter_dir)
tokenizer.save_pretrained(adapter_dir)
print("Saved LoRA adapter to:", adapter_dir)

# 16) Evaluation: generate on validation set and compute metrics
# We'll generate text for each validation tweet and parse label from the generated text (look for 'Label:' line)
def generate_warning(model, tokenizer, instruction, max_new_tokens=64, temperature=0.2):
    # encode instruction only
    inputs = tokenizer(instruction, return_tensors="pt", truncation=True, max_length=max_length).to(model.device)
    with torch.no_grad():
        out = model.generate(**inputs, max_new_tokens=max_new_tokens, temperature=temperature, do_sample=False)
    text = tokenizer.decode(out[0], skip_special_tokens=True)
    # remove the instruction prefix if present
    if text.startswith(instruction):
        text = text[len(instruction):].strip()
    return text

# Put model in eval mode and move to device
model.eval()

preds = []
refs = []
gen_texts = []
for ex in val_df.to_dict(orient="records"):
    instr = ex["instruction"]
    ref_lab = ex["raw_label"]
    gen = generate_warning(model, tokenizer, instr, max_new_tokens=80)
    gen_texts.append(gen)
    # parse: look for "Label:" in generated text
    pred_label = "neither"
    lower = gen.lower()
    if "label:" in lower:
        # extract after label:
        try:
            after = lower.split("label:",1)[1].strip()
            # take first line or until '.'
            first = after.splitlines()[0]
            # match keywords
            if "hate" in first:
                pred_label = "hate_speech"
            elif "offensive" in first:
                pred_label = "offensive_language"
            elif "neutral" in first or "no violation" in first:
                pred_label = "neither"
        except:
            pass
    else:
        # fallback keyword search
        if any(x in lower for x in ["protected group","target"]):
            pred_label = "hate_speech"
        elif any(x in lower for x in ["abusive","offensive","insult"]):
            pred_label = "offensive_language"
        else:
            pred_label = "neither"
    preds.append(pred_label)
    refs.append(ref_lab)

# compute classification metrics
acc = accuracy_score(refs, preds)
prec, rec, f1, _ = precision_recall_fscore_support(refs, preds, labels=["hate_speech","offensive_language","neither"], average=None)
per_label = dict(zip(["hate_speech","offensive_language","neither"], zip(prec, rec, f1)))
macro_precision, macro_recall, macro_f1, _ = precision_recall_fscore_support(refs, preds, average='macro')
print("Accuracy:", acc)
print("Macro P/R/F1:", macro_precision, macro_recall, macro_f1)
print("Per-label (prec,rec,f1):", per_label)

# 17) ROUGE between generated messages and templates (rough idea of generation quality)
import evaluate
rouge = evaluate.load("rouge")
# compute Rouge between generated messages and the target warning messages
refs_msgs = [ex["completion"].split("Message:",1)[1].strip() if "Message:" in ex["completion"] else ex["completion"] for _, ex in val_df.iterrows()]
gen_msgs = []
for gt in gen_texts:
    # try to extract the "Message:" portion if present
    if "message:" in gt.lower():
        g = gt.split("message:",1)[1].strip()
    else:
        # fallback: use entire generation
        g = gt.strip()
    gen_msgs.append(g)

rouge_res = rouge.compute(predictions=gen_msgs, references=refs_msgs)
print("ROUGE-L (approx):", rouge_res.get("rougeL"))

# 18) Quick interactive test
def moderate_text(text):
    instr = (
        "Analyze the following social media post. Output a short classification label and a brief warning or information message "
        "explaining the issue and suggested action. Keep the response <= 50 words.\n\n"
        f"Post: \"{text}\"\n\n"
        "Output format (exactly):\nLabel: <one of: Hate speech | Offensive language | Neutral / No violation>\nMessage: <short message>"
    )
    gen = generate_warning(model, tokenizer, instr, max_new_tokens=80)
    return gen

print("Example moderation for a sample tweet:")
print(moderate_text("I hate those people, they should all disappear."))

# Done. The adapter + tokenizer are saved under adapter_dir.
print("All finished. Adapter saved to:", adapter_dir)

# Colab-ready: Fine-tune LoRA adapter for SmolLM2 (fixed dependency & load_metric error)
# Run cell-by-cell in Colab. Upload labeled_data.csv to the runtime first.

# 0) Install / upgrade dependencies (choose scikit-learn 1.6.x to avoid conflicts)
!pip install -q --upgrade pip
!pip install -q transformers datasets accelerate peft bitsandbytes sentencepiece evaluate scikit-learn==1.6.3 safetensors

# 1) Imports
import os
import random
from pathlib import Path
from typing import List, Dict

import numpy as np
import pandas as pd
import torch

from datasets import Dataset               # don't import load_metric (deprecated)
import evaluate                            # use evaluate for metrics
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_recall_fscore_support, accuracy_score

from transformers import (
    AutoTokenizer,
    AutoModelForCausalLM,
    TrainingArguments,
    Trainer,
)

from peft import (
    get_peft_model,
    LoraConfig,
    TaskType,
    prepare_model_for_kbit_training,
)

# 2) Load CSV (ensure labeled_data.csv is uploaded in Colab Files)
CSV_PATH = "labeled_data.csv"
if not os.path.exists(CSV_PATH):
    raise FileNotFoundError(f"Upload '{CSV_PATH}' to the Colab runtime (left Files pane).")

df = pd.read_csv(CSV_PATH, dtype=str).fillna("")
print("CSV loaded:", df.shape)
display(df.head())

# 3) Normalize/Infer labels -> 'hate_speech', 'offensive_language', 'neither'
def infer_label(row):
    one_hot_cols = ['hate_speech', 'offensive_language', 'neither']
    for c in one_hot_cols:
        if c in row.index:
            val = str(row[c]).strip().lower()
            if val in ("1","true","yes","y","t"):
                return c
    if 'class' in row.index:
        cval = str(row['class']).strip().lower()
        if cval in ("hate_speech","offensive_language","neither"):
            return cval
        if cval.isdigit():
            mapping = {"0":"hate_speech","1":"offensive_language","2":"neither"}
            if cval in mapping:
                return mapping[cval]
    tw = str(row.get('tweet',"")).lower()
    if any(x in tw for x in ["kill","slur","racist","genocide","nazi"]):
        return "hate_speech"
    if any(x in tw for x in ["stupid","idiot","jerk","shut up","screw you","dumb"]):
        return "offensive_language"
    return "neither"

df['label'] = df.apply(infer_label, axis=1)
print("Label distribution:")
print(df['label'].value_counts())

# 4) Create instruction-completion training pairs (SFT style)
TEMPLATE = {
    "hate_speech": {
        "label": "Hate speech",
        "warning": "Warning: This post targets a protected group and may incite hatred. Consider removing it and educating the author."
    },
    "offensive_language": {
        "label": "Offensive language",
        "warning": "Info: This post contains abusive language. Consider warning the user and reviewing community rules."
    },
    "neither": {
        "label": "Neutral / No violation",
        "warning": "Info: This post appears neutral and does not violate policy."
    }
}

def make_example(row):
    tweet = str(row.get('tweet',"")).strip()
    label = row.get('label',"neither")
    instruction = (
        "Analyze the following social media post. Output a short classification label and a brief warning or information message "
        "explaining the issue and suggested action. Keep the response <= 50 words.\n\n"
        f"Post: \"{tweet}\"\n\n"
        "Output format (exactly):\nLabel: <one of: Hate speech | Offensive language | Neutral / No violation>\nMessage: <short message>"
    )
    template = TEMPLATE.get(label, TEMPLATE['neither'])
    completion = f"Label: {template['label']}\nMessage: {template['warning']}"
    return {"instruction": instruction, "completion": completion, "raw_label": label, "tweet": tweet}

examples = [make_example(r) for _, r in df.iterrows() if str(r.get('tweet',"")).strip() != ""]
data_df = pd.DataFrame(examples)
print("Prepared examples:", len(data_df))
display(data_df.sample(min(5,len(data_df))))

# 5) Train/validation split
if len(data_df) < 2:
    raise ValueError("Not enough non-empty examples after preprocessing.")
train_df, val_df = train_test_split(data_df, test_size=0.1, random_state=42, stratify=data_df['raw_label'] if len(data_df)>1 else None)
train_ds = Dataset.from_pandas(train_df.reset_index(drop=True))
val_ds = Dataset.from_pandas(val_df.reset_index(drop=True))
print("Train/Val sizes:", len(train_ds), len(val_ds))

# 6) Choose base model (SmolLM2 variant). Change to a smaller variant if GPU memory is tight.
BASE_MODEL = "unsloth/SmolLM2-360M"  # change if you have different SmolLM2 path

print("Loading tokenizer & model:", BASE_MODEL)
tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, use_fast=False)
if tokenizer.pad_token is None:
    tokenizer.add_special_tokens({'pad_token': '<pad>'})

# Load model with memory-saving options; fallback if 8-bit not available
try:
    model = AutoModelForCausalLM.from_pretrained(
        BASE_MODEL,
        load_in_8bit=True,
        device_map="auto",
        use_safetensors=True,
    )
    print("Model loaded in 8-bit.")
except Exception as e:
    print("8-bit load failed:", e)
    model = AutoModelForCausalLM.from_pretrained(BASE_MODEL, device_map="auto")
    try:
        model.half()
    except Exception:
        pass

# 7) Prepare for k-bit training (PEFT)
model = prepare_model_for_kbit_training(model)

# 8) LoRA config & attach
lora_r = 8
lora_alpha = 16
target_modules = ["q_proj", "k_proj", "v_proj", "o_proj"]  # typical names; safe if some do not exist

peft_config = LoraConfig(
    task_type=TaskType.CAUSAL_LM,
    inference_mode=False,
    r=lora_r,
    lora_alpha=lora_alpha,
    target_modules=target_modules,
    lora_dropout=0.05,
)

model = get_peft_model(model, peft_config)
model.print_trainable_parameters()

# 9) Tokenization & preprocessing for causal LM
max_length = 512

def preprocess_function(batch):
    instructions = batch["instruction"]
    completions = batch["completion"]
    all_inputs = []
    all_labels = []
    all_attn = []
    for instr, comp in zip(instructions, completions):
        # build full prompt: instruction + separator + completion
        full = instr + "\n\n" + comp
        enc_full = tokenizer(full, truncation=True, max_length=max_length, padding='max_length')
        enc_instr = tokenizer(instr, truncation=True, max_length=max_length)
        instr_len = len(enc_instr["input_ids"])
        labels = enc_full["input_ids"].copy()
        # mask instruction tokens so loss computed only on completion
        labels[:instr_len] = [-100] * instr_len
        all_inputs.append(enc_full["input_ids"])
        all_labels.append(labels)
        # attention mask: 1 where token != pad_token_id (we used padding='max_length' so use enc_full["attention_mask"])
        all_attn.append(enc_full["attention_mask"])
    return {"input_ids": all_inputs, "attention_mask": all_attn, "labels": all_labels}

train_encoded = train_ds.map(preprocess_function, batched=True, remove_columns=train_ds.column_names)
eval_encoded = val_ds.map(preprocess_function, batched=True, remove_columns=val_ds.column_names)

# 10) Minimal data collator (works with Trainer)
import torch

def collate_fn(batch):
    input_ids = torch.tensor([b["input_ids"] for b in batch], dtype=torch.long)
    attention_mask = torch.tensor([b["attention_mask"] for b in batch], dtype=torch.long)
    labels = torch.tensor([b["labels"] for b in batch], dtype=torch.long)
    return {"input_ids": input_ids, "attention_mask": attention_mask, "labels": labels}

# 11) Training args
output_dir = "smollm2_lora_adapter_fixed"
training_args = TrainingArguments(
    output_dir=output_dir,
    per_device_train_batch_size=4,
    per_device_eval_batch_size=4,
    gradient_accumulation_steps=4,
    num_train_epochs=3,
    learning_rate=2e-4,
    fp16=True,
    logging_steps=20,
    evaluation_strategy="epoch",
    save_strategy="epoch",
    save_total_limit=2,
    remove_unused_columns=False,
    report_to="none",
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_encoded,
    eval_dataset=eval_encoded,
    data_collator=collate_fn,
    tokenizer=tokenizer,
)

# 12) Start training
trainer.train()

# 13) Save LoRA adapter + tokenizer
adapter_dir = os.path.join(output_dir, "lora_adapter")
model.save_pretrained(adapter_dir)
tokenizer.save_pretrained(adapter_dir)
print("Saved LoRA adapter to:", adapter_dir)

# 14) Evaluation: generate and compute classification metrics (extract label from generated text)
rouge = evaluate.load("rouge")

def generate_text(model, tokenizer, instruction, max_new_tokens=80):
    inputs = tokenizer(instruction, return_tensors="pt", truncation=True, max_length=max_length).to(model.device)
    with torch.no_grad():
        out = model.generate(**inputs, max_new_tokens=max_new_tokens, do_sample=False)
    decoded = tokenizer.decode(out[0], skip_special_tokens=True)
    # Remove repeating instruction prefix if present
    if decoded.startswith(instruction):
        decoded = decoded[len(instruction):].strip()
    return decoded

# put model into eval
model.eval()

preds = []
refs = []
gen_msgs = []
for row in val_df.to_dict(orient="records"):
    instr = row["instruction"]
    ref = row["raw_label"]
    gen = generate_text(model, tokenizer, instr, max_new_tokens=80)
    gen_msgs.append(gen)
    # parse predicted label
    lower = gen.lower()
    pred_label = "neither"
    if "label:" in lower:
        try:
            after = lower.split("label:",1)[1].strip()
            firstline = after.splitlines()[0]
            if "hate" in firstline:
                pred_label = "hate_speech"
            elif "offensive" in firstline:
                pred_label = "offensive_language"
            elif "neutral" in firstline or "no violation" in firstline:
                pred_label = "neither"
        except:
            pred_label = "neither"
    else:
        # fallback keyword heuristics
        if any(x in lower for x in ["protected group", "target", "incite hatred"]):
            pred_label = "hate_speech"
        elif any(x in lower for x in ["abusive","offensive","insult"]):
            pred_label = "offensive_language"
        else:
            pred_label = "neither"
    preds.append(pred_label)
    refs.append(ref)

# compute classification metrics
acc = accuracy_score(refs, preds)
prec, rec, f1, _ = precision_recall_fscore_support(refs, preds, labels=["hate_speech","offensive_language","neither"], average=None, zero_division=0)
per_label = dict(zip(["hate_speech","offensive_language","neither"], zip(prec, rec, f1)))
macro_p, macro_r, macro_f1, _ = precision_recall_fscore_support(refs, preds, average='macro', zero_division=0)

print("Accuracy:", acc)
print("Macro P/R/F1:", macro_p, macro_r, macro_f1)
print("Per-label P/R/F1:", per_label)

# compute ROUGE between generated message portion and reference message
refs_msgs = [r["completion"].split("Message:",1)[1].strip() if "Message:" in r["completion"] else r["completion"] for _, r in val_df.iterrows()]
pred_msgs = []
for g in gen_msgs:
    low = g.lower()
    if "message:" in low:
        # preserve original casing by splitting with case-insensitive technique
        split_index = None
        for token in ("Message:", "message:"):
            if token in g:
                split_index = g.index(token)
                break
        if split_index is not None:
            pred_msgs.append(g[split_index+len("message:"):].strip())
        else:
            pred_msgs.append(g.strip())
    else:
        pred_msgs.append(g.strip())

rouge_res = rouge.compute(predictions=pred_msgs, references=refs_msgs)
print("ROUGE-L:", rouge_res.get("rougeL"))

# 15) Quick interactive test function
def moderate_text(text):
    instr = (
        "Analyze the following social media post. Output a short classification label and a brief warning or information message "
        "explaining the issue and suggested action. Keep the response <= 50 words.\n\n"
        f"Post: \"{text}\"\n\n"
        "Output format (exactly):\nLabel: <one of: Hate speech | Offensive language | Neutral / No violation>\nMessage: <short message>"
    )
    return generate_text(model, tokenizer, instr, max_new_tokens=80)

print("Example moderation:")
print(moderate_text("I hate those people, they should all disappear."))

!pip install -q --upgrade pip
!pip install -q transformers datasets accelerate peft bitsandbytes sentencepiece evaluate scikit-learn==1.6.3 safetensors

# 1) Imports
import os
import random
from pathlib import Path
from typing import List, Dict

import numpy as np
import pandas as pd
import torch

from datasets import Dataset               # don't import load_metric (deprecated)
import evaluate                            # use evaluate for metrics
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_recall_fscore_support, accuracy_score

from transformers import (
    AutoTokenizer,
    AutoModelForCausalLM,
    TrainingArguments,
    Trainer,
)

from peft import (
    get_peft_model,
    LoraConfig,
    TaskType,
    prepare_model_for_kbit_training,
)

# 2) Load CSV (ensure labeled_data.csv is uploaded in Colab Files)
CSV_PATH = "labeled_data.csv"
if not os.path.exists(CSV_PATH):
    raise FileNotFoundError(f"Upload '{CSV_PATH}' to the Colab runtime (left Files pane).")

df = pd.read_csv(CSV_PATH, dtype=str).fillna("")
print("CSV loaded:", df.shape)
display(df.head())



# Colab-ready: Fine-tune LoRA adapter for SmolLM2 (fixed dependency & load_metric error)
# Run cell-by-cell in Colab. Upload labeled_data.csv to the runtime first.

# 0) Install / upgrade dependencies (choose scikit-learn 1.6.x to avoid conflicts)
!pip install -q --upgrade pip
!pip install -q transformers datasets accelerate peft bitsandbytes sentencepiece evaluate scikit-learn==1.6.3 safetensors

# 1) Imports
import os
import random
from pathlib import Path
from typing import List, Dict

import numpy as np
import pandas as pd
import torch

from datasets import Dataset               # don't import load_metric (deprecated)
import evaluate                            # use evaluate for metrics
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_recall_fscore_support, accuracy_score

from transformers import (
    AutoTokenizer,
    AutoModelForCausalLM,
    TrainingArguments,
    Trainer,
)

from peft import (
    get_peft_model,
    LoraConfig,
    TaskType,
    prepare_model_for_kbit_training,
)

# 2) Load CSV (ensure labeled_data.csv is uploaded in Colab Files)
CSV_PATH = "labeled_data.csv"
if not os.path.exists(CSV_PATH):
    raise FileNotFoundError(f"Upload '{CSV_PATH}' to the Colab runtime (left Files pane).")

df = pd.read_csv(CSV_PATH, dtype=str).fillna("")
print("CSV loaded:", df.shape)
display(df.head())

# 3) Normalize/Infer labels -> 'hate_speech', 'offensive_language', 'neither'
def infer_label(row):
    one_hot_cols = ['hate_speech', 'offensive_language', 'neither']
    for c in one_hot_cols:
        if c in row.index:
            val = str(row[c]).strip().lower()
            if val in ("1","true","yes","y","t"):
                return c
    if 'class' in row.index:
        cval = str(row['class']).strip().lower()
        if cval in ("hate_speech","offensive_language","neither"):
            return cval
        if cval.isdigit():
            mapping = {"0":"hate_speech","1":"offensive_language","2":"neither"}
            if cval in mapping:
                return mapping[cval]
    tw = str(row.get('tweet',"")).lower()
    if any(x in tw for x in ["kill","slur","racist","genocide","nazi"]):
        return "hate_speech"
    if any(x in tw for x in ["stupid","idiot","jerk","shut up","screw you","dumb"]):
        return "offensive_language"
    return "neither"

df['label'] = df.apply(infer_label, axis=1)
print("Label distribution:")
print(df['label'].value_counts())

# 4) Create instruction-completion training pairs (SFT style)
TEMPLATE = {
    "hate_speech": {
        "label": "Hate speech",
        "warning": "Warning: This post targets a protected group and may incite hatred. Consider removing it and educating the author."
    },
    "offensive_language": {
        "label": "Offensive language",
        "warning": "Info: This post contains abusive language. Consider warning the user and reviewing community rules."
    },
    "neither": {
        "label": "Neutral / No violation",
        "warning": "Info: This post appears neutral and does not violate policy."
    }
}

def make_example(row):
    tweet = str(row.get('tweet',"")).strip()
    label = row.get('label',"neither")
    instruction = (
        "Analyze the following social media post. Output a short classification label and a brief warning or information message "
        "explaining the issue and suggested action. Keep the response <= 50 words.\n\n"
        f"Post: \"{tweet}\"\n\n"
        "Output format (exactly):\nLabel: <one of: Hate speech | Offensive language | Neutral / No violation>\nMessage: <short message>"
    )
    template = TEMPLATE.get(label, TEMPLATE['neither'])
    completion = f"Label: {template['label']}\nMessage: {template['warning']}"
    return {"instruction": instruction, "completion": completion, "raw_label": label, "tweet": tweet}

examples = [make_example(r) for _, r in df.iterrows() if str(r.get('tweet',"")).strip() != ""]
data_df = pd.DataFrame(examples)
print("Prepared examples:", len(data_df))
display(data_df.sample(min(5,len(data_df))))

# 5) Train/validation split
if len(data_df) < 2:
    raise ValueError("Not enough non-empty examples after preprocessing.")
train_df, val_df = train_test_split(data_df, test_size=0.1, random_state=42, stratify=data_df['raw_label'] if len(data_df)>1 else None)
train_ds = Dataset.from_pandas(train_df.reset_index(drop=True))
val_ds = Dataset.from_pandas(val_df.reset_index(drop=True))
print("Train/Val sizes:", len(train_ds), len(val_ds))

# 6) Choose base model (SmolLM2 variant). Change to a smaller variant if GPU memory is tight.
BASE_MODEL = "unsloth/SmolLM2-360M"  # change if you have different SmolLM2 path

print("Loading tokenizer & model:", BASE_MODEL)
tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, use_fast=False)
if tokenizer.pad_token is None:
    tokenizer.add_special_tokens({'pad_token': '<pad>'})

# Load model with memory-saving options; fallback if 8-bit not available
try:
    model = AutoModelForCausalLM.from_pretrained(
        BASE_MODEL,
        load_in_8bit=True,
        device_map="auto",
        use_safetensors=True,
    )
    print("Model loaded in 8-bit.")
except Exception as e:
    print("8-bit load failed:", e)
    model = AutoModelForCausalLM.from_pretrained(BASE_MODEL, device_map="auto")
    try:
        model.half()
    except Exception:
        pass

# 7) Prepare for k-bit training (PEFT)
model = prepare_model_for_kbit_training(model)

# 8) LoRA config & attach
lora_r = 8
lora_alpha = 16
target_modules = ["q_proj", "k_proj", "v_proj", "o_proj"]  # typical names; safe if some do not exist

peft_config = LoraConfig(
    task_type=TaskType.CAUSAL_LM,
    inference_mode=False,
    r=lora_r,
    lora_alpha=lora_alpha,
    target_modules=target_modules,
    lora_dropout=0.05,
)

model = get_peft_model(model, peft_config)
model.print_trainable_parameters()

# 9) Tokenization & preprocessing for causal LM
max_length = 512

def preprocess_function(batch):
    instructions = batch["instruction"]
    completions = batch["completion"]
    all_inputs = []
    all_labels = []
    all_attn = []
    for instr, comp in zip(instructions, completions):
        # build full prompt: instruction + separator + completion
        full = instr + "\n\n" + comp
        enc_full = tokenizer(full, truncation=True, max_length=max_length, padding='max_length')
        enc_instr = tokenizer(instr, truncation=True, max_length=max_length)
        instr_len = len(enc_instr["input_ids"])
        labels = enc_full["input_ids"].copy()
        # mask instruction tokens so loss computed only on completion
        labels[:instr_len] = [-100] * instr_len
        all_inputs.append(enc_full["input_ids"])
        all_labels.append(labels)
        # attention mask: 1 where token != pad_token_id (we used padding='max_length' so use enc_full["attention_mask"])
        all_attn.append(enc_full["attention_mask"])
    return {"input_ids": all_inputs, "attention_mask": all_attn, "labels": all_labels}

train_encoded = train_ds.map(preprocess_function, batched=True, remove_columns=train_ds.column_names)
eval_encoded = val_ds.map(preprocess_function, batched=True, remove_columns=val_ds.column_names)

# 10) Minimal data collator (works with Trainer)
import torch

def collate_fn(batch):
    input_ids = torch.tensor([b["input_ids"] for b in batch], dtype=torch.long)
    attention_mask = torch.tensor([b["attention_mask"] for b in batch], dtype=torch.long)
    labels = torch.tensor([b["labels"] for b in batch], dtype=torch.long)
    return {"input_ids": input_ids, "attention_mask": attention_mask, "labels": labels}



# ====== TRAINING + TRAINER (robust across transformers versions) ======
import warnings
import inspect

# output_dir already defined earlier in notebook; if not, set:
output_dir = "smollm2_lora_adapter_fixed"

# Prepare kwargs for TrainingArguments
base_ta_kwargs = dict(
    output_dir=output_dir,
    per_device_train_batch_size=4,
    per_device_eval_batch_size=4,
    gradient_accumulation_steps=4,
    num_train_epochs=3,
    learning_rate=2e-4,
    fp16=True,
    logging_steps=20,
    # keep save_total_limit (widely supported)
    save_total_limit=2,
    remove_unused_columns=False,
    report_to="none",
)

# Newer/optional kwargs we *prefer* to use if available:
preferred_extra_kwargs = dict(
    evaluation_strategy="epoch",
    save_strategy="epoch",
)

# Try to create TrainingArguments with preferred extras, otherwise fall back
try:
    training_args = TrainingArguments(**{**base_ta_kwargs, **preferred_extra_kwargs})
    print("Created TrainingArguments with evaluation_strategy and save_strategy.")
except TypeError as e:
    warnings.warn(
        "TrainingArguments rejected some kwargs (likely older transformers). "
        "Falling back to a minimal TrainingArguments configuration. "
        "Original error: " + str(e)
    )
    # fallback: create without evaluation/save strategy
    training_args = TrainingArguments(**base_ta_kwargs)
    print("Created fallback TrainingArguments (no evaluation_strategy/save_strategy).")

# Minimal collate_fn defined earlier; ensure it exists. If not, recreate:
import torch
def collate_fn(batch):
    input_ids = torch.tensor([b["input_ids"] for b in batch], dtype=torch.long)
    attention_mask = torch.tensor([b["attention_mask"] for b in batch], dtype=torch.long)
    labels = torch.tensor([b["labels"] for b in batch], dtype=torch.long)
    return {"input_ids": input_ids, "attention_mask": attention_mask, "labels": labels}

# Create Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_encoded,
    eval_dataset=eval_encoded if 'eval_encoded' in globals() else None,
    data_collator=collate_fn,
    tokenizer=tokenizer,
)

# Train
train_result = trainer.train()
print("Training finished. train_result:", train_result)

# Regardless of whether evaluation_strategy ran during training,
# run a final evaluation now (this will work across versions).
try:
    eval_res = trainer.evaluate(eval_dataset=eval_encoded)
    print("Trainer.evaluate() results:")
    print(eval_res)
except Exception as e:
    warnings.warn(f"trainer.evaluate() raised an exception: {e}. You can still run manual evaluation below.")

# Save model + adapter + tokenizer
adapter_dir = os.path.join(output_dir, "lora_adapter")
model.save_pretrained(adapter_dir)
tokenizer.save_pretrained(adapter_dir)
print("Saved LoRA adapter + tokenizer to:", adapter_dir)

# ---------------- Manual generation + metrics (keeps previous behaviour) ----------------
# If you already have the manual generation/evaluation code below (as in the notebook), keep it.
# Otherwise run the same generation + classification-metrics + ROUGE code shown previously, e.g.:

import evaluate
rouge = evaluate.load("rouge")
from sklearn.metrics import precision_recall_fscore_support, accuracy_score

def generate_text(model, tokenizer, instruction, max_new_tokens=80):
    inputs = tokenizer(instruction, return_tensors="pt", truncation=True, max_length=512).to(model.device)
    with torch.no_grad():
        out = model.generate(**inputs, max_new_tokens=max_new_tokens, do_sample=False)
    decoded = tokenizer.decode(out[0], skip_special_tokens=True)
    if decoded.startswith(instruction):
        decoded = decoded[len(instruction):].strip()
    return decoded

# create lists to compute metrics
preds = []
refs = []
gen_msgs = []

for row in val_df.to_dict(orient="records"):
    instr = row["instruction"]
    ref = row["raw_label"]
    gen = generate_text(model, tokenizer, instr, max_new_tokens=80)
    gen_msgs.append(gen)
    lower = gen.lower()
    pred_label = "neither"
    if "label:" in lower:
        try:
            after = lower.split("label:", 1)[1].strip()
            firstline = after.splitlines()[0]
            if "hate" in firstline:
                pred_label = "hate_speech"
            elif "offensive" in firstline:
                pred_label = "offensive_language"
            elif "neutral" in firstline or "no violation" in firstline:
                pred_label = "neither"
        except Exception:
            pred_label = "neither"
    else:
        if any(x in lower for x in ["protected group", "target", "incite hatred"]):
            pred_label = "hate_speech"
        elif any(x in lower for x in ["abusive", "offensive", "insult"]):
            pred_label = "offensive_language"
        else:
            pred_label = "neither"
    preds.append(pred_label)
    refs.append(ref)

# classification metrics
acc = accuracy_score(refs, preds)
prec, rec, f1, _ = precision_recall_fscore_support(refs, preds, labels=["hate_speech", "offensive_language", "neither"], average=None, zero_division=0)
per_label = dict(zip(["hate_speech","offensive_language","neither"], zip(prec, rec, f1)))
macro_p, macro_r, macro_f1, _ = precision_recall_fscore_support(refs, preds, average='macro', zero_division=0)

print("Accuracy:", acc)
print("Macro P/R/F1:", macro_p, macro_r, macro_f1)
print("Per-label P/R/F1:", per_label)

# ROUGE for generated messages vs reference templates
refs_msgs = [r["completion"].split("Message:",1)[1].strip() if "Message:" in r["completion"] else r["completion"] for _, r in val_df.iterrows()]
pred_msgs = []
for g in gen_msgs:
    low = g.lower()
    if "message:" in low:
        # attempt case-insensitive split while keeping original casing
        idx = None
        for token in ("Message:", "message:"):
            if token in g:
                idx = g.index(token)
                break
        if idx is not None:
            pred_msgs.append(g[idx + len("message:"):].strip())
        else:
            pred_msgs.append(g.strip())
    else:
        pred_msgs.append(g.strip())

try:
    rouge_res = rouge.compute(predictions=pred_msgs, references=refs_msgs)
    print("ROUGE-L:", rouge_res.get("rougeL"))
except Exception as e:
    warnings.warn("ROUGE computation failed: " + str(e))

# Quick interactive check
def moderate_text(text):
    instr = (
        "Analyze the following social media post. Output a short classification label and a brief warning or information message "
        "explaining the issue and suggested action. Keep the response <= 50 words.\n\n"
        f"Post: \"{text}\"\n\n"
        "Output format (exactly):\nLabel: <one of: Hate speech | Offensive language | Neutral / No violation>\nMessage: <short message>"
    )
    return generate_text(model, tokenizer, instr, max_new_tokens=80)

print("Example moderation:")
print(moderate_text("I hate those people, they should all disappear."))













